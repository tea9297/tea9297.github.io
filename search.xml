<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2024 updates</title>
    <url>/2024/12/31/2024%20updates/</url>
    <content><![CDATA[<h2 id="10-04-0-8-63"><a href="#10-04-0-8-63" class="headerlink" title="10&#x2F;04(0.8.63)"></a>10&#x2F;04(0.8.63)</h2><ul>
<li>Doc_QA 新增ask_image函數，可輸入圖片與問題到多模態模型(如gpt-4o, llama3.2-Vision)中(見<a href="/2024/12/29/ask_image/">ask_image</a>)</li>
<li>Doc_QA 新增max_output_tokens參數，用以限制模型最大輸出長度</li>
</ul>
<h2 id="08-15-0-8-56"><a href="#08-15-0-8-56" class="headerlink" title="08&#x2F;15(0.8.56)"></a>08&#x2F;15(0.8.56)</h2><ul>
<li>db 新增 <em><strong>extract_db_by_file</strong></em> 和 <em><strong>extract_db_by_keyword</strong></em> 可從chromadb中取出特定文件檔案或特定id的db(見<a href="/2024/12/26/%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B">嵌入模型</a>)</li>
</ul>
<h2 id="08-08-0-8-53"><a href="#08-08-0-8-53" class="headerlink" title="08&#x2F;08(0.8.53)"></a>08&#x2F;08(0.8.53)</h2><ul>
<li>Doc_QA 新增stream參數，若stream&#x3D;True，則回傳值為generator (見 <a href="/2024/12/29/get_response/">get_response</a>)</li>
<li><em><strong>get_response</strong></em> 和 <em><strong>ask_self</strong></em> 新增history_messages參數來傳遞聊天紀錄訊息 (見<a href="/2024/12/29/get_response/">get_response</a>)</li>
<li><em><strong>get_response</strong></em> 可傳入dbs物件，避免重複load chromadb (見 <a href="/2024/12/29/get_response/">get_response</a>)</li>
<li>prompt_format_type參數新增”chat_gpt”和”chat_mistral”，用來傳遞非str type輸入給語言模型 如([{“role”:current_role, “content”:prompt}])， (見 <a href="/2024/12/26/%E6%8F%90%E7%A4%BA%E6%A0%BC%E5%BC%8F/">提示格式</a>)</li>
<li>輔助函數新增 call_model, call_batch_model, call_stream_model (見 <a href="/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a>)</li>
<li>輔助函數新增 self-rag (見 <a href="/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a>)</li>
<li>語言模型物件(LLM)和嵌入模型物件(Embeddings)可直接傳入<em><strong>Doc_QA</strong></em>, <em><strong>Eval</strong></em>,和 <em><strong>Summary</strong></em>，避免重複宣告(見 <a href="/2024/12/26/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">語言模型</a> <a href="/2024/12/26/%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">嵌入模型</a>)</li>
<li>內建 FAST API，可使用 “akasha api (–port port –host host –workers num_of_workers) 啟動 (見 <a href="/2024/12/26/FAST%20API/">FAST API</a>)</li>
</ul>
<h2 id="05-29-0-8-34"><a href="#05-29-0-8-34" class="headerlink" title="05&#x2F;29(0.8.34)"></a>05&#x2F;29(0.8.34)</h2><ul>
<li>新增stream output  <a href="/2024/12/26/%E6%B5%81%E8%BC%B8%E5%87%BA/">流輸出</a></li>
</ul>
<h2 id="05-09-0-8-28"><a href="#05-09-0-8-28" class="headerlink" title="05&#x2F;09(0.8.28)"></a>05&#x2F;09(0.8.28)</h2><ul>
<li>新增語言模型類別: <em><strong>gptq</strong></em></li>
<li><em><strong>remote</strong></em> 語言模型類別更新為streaming print out</li>
<li>基於參數 <em><strong>doc_path</strong></em> 的輸入類型，您可以使用 <em><strong>get_response</strong></em> 來運行 <em><strong>ask_whole_file</strong></em> 和 <em><strong>ask_self</strong></em>（若 <em><strong>doc_path</strong></em> 是單一文件路徑，則運行 <em><strong>ask_whole_file</strong></em>；如果 <em><strong>doc_path</strong></em> 是一段或多段文字，則運行 <em><strong>ask_self</strong></em>）。</li>
<li><em><strong>search type auto</strong></em> 改為 <em><strong>auto</strong></em> 和 <em><strong>auto_rerank</strong></em>，差別為在找不到足夠相似的文件段落時，是否使用rerank模型</li>
<li><em><strong>Doc_QA</strong></em> 新增 <em><strong>rerun_ask_agent</strong></em> 功能，可更改prompt並重新運行 ask_agent。</li>
<li><em><strong>Eval create_questionset</strong></em>添加參考文件名稱到產生的問題中。</li>
</ul>
<h2 id="04-26-0-8-25"><a href="#04-26-0-8-25" class="headerlink" title="04&#x2F;26(0.8.25)"></a>04&#x2F;26(0.8.25)</h2><ul>
<li><p>新增windows使用者透過WSL安裝ubuntu和anaconda 的使用說明。</p>
</li>
<li><p>dev-ui image 不再使用ccchang0518&#x2F;akasha-dev-ui 改用 ccchang0518&#x2F;akasha-lab:0.6</p>
</li>
</ul>
<h2 id="04-17-0-8-25"><a href="#04-17-0-8-25" class="headerlink" title="04&#x2F;17 (0.8.25)"></a>04&#x2F;17 (0.8.25)</h2><ul>
<li><p>在summary中添加參數 <strong>consecutive_merge_failures</strong> 以防止需要摘要段落持續無法縮減。</p>
</li>
<li><p>在summary中加入進度條。（請注意，<strong>map_reduce</strong> 方法的進度條僅為估計。）</p>
</li>
<li><p>在helper module中，新增 <strong>call_translator</strong> 和 <strong>call_JSON_formatter</strong> 的函數。這些函數有助於利用 LLM 進行翻譯並將輸出格式化為 JSON 格式。</p>
</li>
<li><p>OpenAI 和 Hugging Face 文本生成模型的標準輸出（stdout）改為即時流模式。</p>
</li>
</ul>
<h2 id="04-11-0-8-24"><a href="#04-11-0-8-24" class="headerlink" title="04&#x2F;11 (0.8.24)"></a>04&#x2F;11 (0.8.24)</h2><ul>
<li>-參數<strong>questionset_path</strong>:不再使用參數questionset_path，改用questionset_file</li>
</ul>
<h2 id="04-11-0-8-24-1"><a href="#04-11-0-8-24-1" class="headerlink" title="04&#x2F;11 (0.8.24)"></a>04&#x2F;11 (0.8.24)</h2><ul>
<li>新增參數 <strong>keep_logs</strong>如果為True會儲存每次執行的資料和結果，預設為False</li>
<li>預設不會安裝llama-cpp-python套件，若想使用llama-cpp模型，請使用 pip install akasha-terminal[llama-cpp]安裝</li>
</ul>
<h2 id="04-10-0-8-23"><a href="#04-10-0-8-23" class="headerlink" title="04&#x2F;10 (0.8.23)"></a>04&#x2F;10 (0.8.23)</h2><ul>
<li><strong>HUGGINGFACEHUB_API_TOKEN</strong>:不再使用環境變數 HUGGINGFACEHUB_API_TOKEN， 使用HF_TOKEN匯入 key</li>
</ul>
<h2 id="03-27-0-8-23"><a href="#03-27-0-8-23" class="headerlink" title="03&#x2F;27 (0.8.23)"></a>03&#x2F;27 (0.8.23)</h2><ul>
<li><strong>Summary:</strong> Summary新增選項auto_translate將摘要翻譯成目標語言, <a href="/2024/12/27/summary/">summary</a></li>
<li><strong>summarize_articles:</strong> Summary新增summarize_articles函數，將str或list做摘要</li>
<li><strong>language:</strong> 在akasha.format中新增語言對照表</li>
</ul>
<h2 id="03-22-0-8-21"><a href="#03-22-0-8-21" class="headerlink" title="03&#x2F;22 (0.8.21)"></a>03&#x2F;22 (0.8.21)</h2><ul>
<li><strong>agent module:</strong> 新增代理模組，可以自定義tools和agents, <a href="/2024/12/26/%E4%BB%A3%E7%90%86/">代理</a></li>
<li><strong>add document format:</strong> 新增可讀取文件類別.pptx .md</li>
</ul>
<h2 id="03-08-0-8-20"><a href="#03-08-0-8-20" class="headerlink" title="03&#x2F;08 (0.8.20)"></a>03&#x2F;08 (0.8.20)</h2><ul>
<li><strong>search bm25:</strong> 在 search_type中, 新增 bm25選項, <a href="/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><strong>search auto:</strong> 在 search_type中, 新增 auto選項, <a href="/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><strong>Doc_QA ask_agent:</strong> 在akasha.Doc_QA中， 新增ask_agent，使用self-ask prompting回答較為複雜的問題, <a href="/2024/12/29/ask_agent/">ask_agent</a></li>
</ul>
<h2 id="02-26-0-8-19"><a href="#02-26-0-8-19" class="headerlink" title="02&#x2F;26 (0.8.19)"></a>02&#x2F;26 (0.8.19)</h2><ul>
<li><p><strong>JSON_formatter:</strong> 在 akasha.prompts, 新增 JSON_formatter_list 和 JSON_formatter_dict,  <a href="/2024/12/25/JSON%E6%A0%BC%E5%BC%8F/">JSON格式</a></p>
</li>
<li><p><strong>topK:</strong> 不再使用參數topK，使用max_doc_len來決定參考文件的選取上限。 </p>
</li>
<li><p><strong>use_rerank:</strong> 新增use_rerank參數，在文件相似度搜尋完之後使用rerank模型更精準排序文件與使用者問題的相關性，預設False。</p>
</li>
<li><p><strong>topic_questionset:</strong> akasha.eval中新增topic_questionset，用以產生特定主題的測試問題集。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>目錄</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>akashalab-Datasets</title>
    <url>/2024/01/01/DEV-Datasets/</url>
    <content><![CDATA[<h2 id="創建Dataset"><a href="#創建Dataset" class="headerlink" title="創建Dataset"></a>創建Dataset</h2><p>Dataset為保存一個或多個文件檔的設定檔。<br>至New Dataset頁面，輸入dataset名稱與描述，並上傳dataset所需的文件檔案(.txt、.pdf、.docx)</p>
<p><img src="https://hackmd.io/_uploads/HkE2pClcT.png" alt="image"></p>
</br>
</br>

<p>可選擇是否分享dataset給其他使用者<br><img src="https://hackmd.io/_uploads/HJS8C0gcT.png" alt="image"></p>
</br>
</br>

<p>按下 “Create Dataset”，創建dataset 成功</p>
<p><img src="https://hackmd.io/_uploads/HyJc0Re5a.png" alt="image"></p>
</br>
</br>

<p>:::warning<br>同一使用者無法創建相同名稱的Dataset，不同使用者可以創建相同名稱的Dataset<br>:::<br><img src="https://hackmd.io/_uploads/HkvCA0l5p.png" alt="image"></p>
</br>
</br>

<h2 id="檢視Dataset"><a href="#檢視Dataset" class="headerlink" title="檢視Dataset"></a>檢視Dataset</h2><p>創建完Dataset後，可至My Dataset頁面檢視，勾選Shared Datasets按鈕後也會顯示別人分享的Datasets，自己創建的Dataset可以刪除，但無法刪除別人分享的Dataset。</p>
<p><img src="https://hackmd.io/_uploads/rkO8kJb5a.png" alt="image"></p>
</br>
</br>

<h2 id="更新Dataset"><a href="#更新Dataset" class="headerlink" title="更新Dataset"></a>更新Dataset</h2><p>若要更新Dataset資訊，可至Update Dataset頁面，選擇要更新的Dataset後，便可以更改Dataset名稱、描述，也可以新增或刪除文件、分享者。<br><img src="https://hackmd.io/_uploads/S1uye1-56.png" alt="image"><br><img src="https://hackmd.io/_uploads/H1xee1-q6.png" alt="image"></p>
]]></content>
      <categories>
        <category>akasha-lab</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>akashalab-Knowledges</title>
    <url>/2024/01/01/DEV-Knowledges/</url>
    <content><![CDATA[<h2 id="創建Knowledge"><a href="#創建Knowledge" class="headerlink" title="創建Knowledge"></a>創建Knowledge</h2><p>knowledge為一個保存資料集(Datasets)和搜尋參數的設定檔，可以直接使用knowledge來使用文檔問答。<br>至New Knowledge頁面，輸入Knowledge名稱，選擇嵌入模型，選擇文件段落大小，選擇Dataset(可以多個)，預設為選擇所有文件檔案，也可以各個檔案逐一勾選。</p>
<p><img src="https://hackmd.io/_uploads/Bk9a71bq6.png" alt="image"></p>
</br>
</br>hhh

<p>可選擇是否分享Knowledge給其他使用者<br><img src="https://hackmd.io/_uploads/ry2K4yZ9p.png" alt="image"></p>
</br>
</br>

<p>按下 “Create Knowledge”，會為每個文件產生向量db，因此可能需要等待一段時間。<br><img src="https://hackmd.io/_uploads/Sy3kS1bc6.png" alt="image"></p>
</br>
</br>

<p>:::warning<br>同一使用者無法創建相同名稱的Knowledge，不同使用者可以創建相同名稱的Knowledge<br>:::<br><img src="https://hackmd.io/_uploads/Ski7By-5T.png" alt="image"></p>
</br>
</br>

<h2 id="檢視Knowledge"><a href="#檢視Knowledge" class="headerlink" title="檢視Knowledge"></a>檢視Knowledge</h2><p>創建完Knowledge後，可至My Knowledges頁面檢視，勾選Shared Knowledges按鈕後也會顯示別人分享的Knowledges，自己創建的Knowledge可以刪除，但無法刪除別人分享的Knowledge。</p>
<p><img src="https://hackmd.io/_uploads/Hkq2HJbca.png" alt="image"></p>
</br>
</br>

<h2 id="更新Knowledge"><a href="#更新Knowledge" class="headerlink" title="更新Knowledge"></a>更新Knowledge</h2><p>若要更新Knowledge資訊，可至Update Knowledge頁面，選擇要更新的Knowledge後，便可以更改Knowledge名稱、描述，也可以新增或刪除文件、分享者。<br><img src="https://hackmd.io/_uploads/r1RvLJZqa.png" alt="image"><br><img src="https://hackmd.io/_uploads/B1afL1b56.png" alt="image"></p>
]]></content>
      <categories>
        <category>akasha-lab</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>akashalab-安裝&amp;執行</title>
    <url>/2024/01/01/DEV-%E5%AE%89%E8%A3%9D&amp;%E5%9F%B7%E8%A1%8C/</url>
    <content><![CDATA[<h2 id="pip-安裝"><a href="#pip-安裝" class="headerlink" title="pip 安裝"></a>pip 安裝</h2><ol>
<li>下載或git clone akasha ui-dev專案分支到你的資料夾 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> --branch ui-dev https://github.com/iii-org/akasha.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> akasha</span></span><br></pre></td></tr></table></figure></li>
<li>安裝所需python套件 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python -m pip install -r requirements.txt</span></span><br></pre></td></tr></table></figure></li>
<li>啟動fast api server 和 streamlit 介面 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">nohup</span> /bin/bash -c <span class="string">&quot;uvicorn api:app &amp;&quot;</span> &amp;&amp; streamlit run main.py</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p><img src="https://hackmd.io/_uploads/HJKlJ2lqp.png" alt="image"></p>
<h2 id="Docker-安裝"><a href="#Docker-安裝" class="headerlink" title="Docker 安裝"></a>Docker 安裝</h2><p>在某些情況之下採用pip 安裝，無法開啟dev-ui，或許這時候可以考慮使用docker</p>
<ol>
<li>下載或git clone akasha ui-dev專案分支到你的資料夾 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> --branch ui-dev https://github.com/iii-org/akasha.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> akasha</span></span><br></pre></td></tr></table></figure></li>
<li>(optional) 編輯 install.env 檔案 <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">## install.env</span><br><span class="line">MODEL=./model    # 存放語言模型的資料夾</span><br><span class="line">CONFIG=./config # 存放dataset, knowledge 配置檔的資料夾</span><br><span class="line">DOCS=./docs # 存放文件的資料夾</span><br><span class="line">IMAGE_NAME=akasha_dev_ui</span><br><span class="line">IMAGE_VERSION=0.1</span><br></pre></td></tr></table></figure></li>
<li>執行安裝 script <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">sudo</span> bash install.sh</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="預設openAI-key"><a href="#預設openAI-key" class="headerlink" title="預設openAI key"></a>預設openAI key</h3><p>如果您想要添加預設的 OpenAI API 密鑰或 Azure OpenAI API 密鑰，以便每個用戶都可以直接使用它，在第二步中，您可以在 <em><strong>install.env</strong></em> 文件中添加您的預設密鑰。<br>這將在你的config目錄中創建一個 <em><strong>default_key.json</strong></em> 文件，你可以更改該文件中的密鑰值以便在啟動akasha_dev_ui後更改或刪除密鑰。</p>
<h3 id="openAI"><a href="#openAI" class="headerlink" title="openAI:"></a>openAI:</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install.env ##</span></span><br><span class="line">MODEL=./model   </span><br><span class="line">CONFIG=./config </span><br><span class="line">DOCS=./docs </span><br><span class="line">IMAGE_NAME=akasha-lab</span><br><span class="line">IMAGE_VERSION=0.6</span><br><span class="line">DEFAULT_OPENAI_API_KEY=&#123;your openAI key&#125;</span><br></pre></td></tr></table></figure>



<h3 id="Azure-openAI"><a href="#Azure-openAI" class="headerlink" title="Azure openAI:"></a>Azure openAI:</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install.env ##</span></span><br><span class="line">MODEL=./model   </span><br><span class="line">CONFIG=./config </span><br><span class="line">DOCS=./docs </span><br><span class="line">IMAGE_NAME=akasha_dev_ui</span><br><span class="line">IMAGE_VERSION=0.6</span><br><span class="line">DEFAULT_AZURE_API_KEY=&#123;your Azure key&#125;</span><br><span class="line">DEFAULT_AZURE_API_BASE=&#123;your Azure base url&#125;</span><br></pre></td></tr></table></figure>



<br/>
<br/>


<h2 id="使用docker-image建構container"><a href="#使用docker-image建構container" class="headerlink" title="使用docker image建構container"></a>使用docker image建構container</h2><p>1.創建資料夾儲存模型、文件資料</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p config</span><br><span class="line"><span class="built_in">mkdir</span> -p model</span><br><span class="line"><span class="built_in">mkdir</span> -p docs</span><br><span class="line"><span class="built_in">mkdir</span> -p chromadb</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2.創建帳號yaml檔accounts.yaml</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cookie:</span><br><span class="line">  expiry_days: 30</span><br><span class="line">  key: random_signature_key</span><br><span class="line">  name: random_cookie_name</span><br><span class="line">credentials:</span><br><span class="line">  usernames:</span><br><span class="line">    cws:</span><br><span class="line">      email: cws@gmail.com</span><br><span class="line">      name: cws</span><br><span class="line">      password: $2b$12$jCB8MeVqMc3jWDynjNyeVeLS8IWBduxnX362gLfJ1KIkeTPH9KYha</span><br><span class="line">  emails: []</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>3.從docker hub下載image並執行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker pull ccchang0518/akasha-lab:0.6</span><br><span class="line"><span class="built_in">sudo</span> docker run -v ./model:/app/model -v ./config:/app/config -v ./docs:/app/docs -v ./chromadb:/app/chromadb -v ./accounts.yaml:/app/accounts.yaml -p 8501:8501 --name akasha_dev_ui ccchang0518/akasha-lab:0.6</span><br></pre></td></tr></table></figure>

<br/>
<br/>


<h2 id="使用API"><a href="#使用API" class="headerlink" title="使用API"></a>使用API</h2><p>若要直接串接akasha dev-ui API，啟動fastapi後，可至docs查詢API functions (<a href="http://127.0.0.1:8000/docs">http://127.0.0.1:8000/docs</a>)</p>
<p><img src="https://hackmd.io/_uploads/HkbuIKLAp.png" alt="image"></p>
<br/>
<br/>

<p>若為docker安裝請使用-p {port}:8000 開啟fastapi port</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker run -v ./model:/app/model -v ./config:/app/config -v ./docs:/app/docs -v ./chromadb:/app/chromadb -v ./accounts.yaml:/app/accounts.yaml -p 8000:8000 -p 8501:8501 --name akasha-lab akasha-lab:0.6</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>akasha-lab</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>akashalab-設定</title>
    <url>/2024/01/01/DEV-%E8%A8%AD%E5%AE%9A/</url>
    <content><![CDATA[<h2 id="API-KEY"><a href="#API-KEY" class="headerlink" title="API KEY"></a>API KEY</h2><p>若要使用openAI的模型，必須輸入API KEY，可選擇openAI或是Azure openAI其一<br>如範例，選擇使用Azure openAI後，輸入key值與URL，按下儲存，若顯示成功，便成功添加API KEY。</p>
<p><img src="https://hackmd.io/_uploads/S1dU30xca.png" alt="image"></p>
<p>若勾選左下角”Save Permanently”便會將key值儲存至config中，下次登入也可以直接使用。</p>
<p><img src="https://hackmd.io/_uploads/BJgE53Cl9T.png" alt="image"></p>
</br>
</br>

<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><p>History分頁可下載文檔問答的紀錄，並下載成.txt或.json檔案。<br><img src="https://hackmd.io/_uploads/SJBzpRlq6.png" alt="image"></p>
<h2 id="Account"><a href="#Account" class="headerlink" title="Account"></a>Account</h2><p>Account分頁可更改密碼或是刪除帳號<br><img src="https://hackmd.io/_uploads/SkYEaAx5a.png" alt="image"></p>
]]></content>
      <categories>
        <category>akasha-lab</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>akashalab-註冊帳號</title>
    <url>/2024/01/01/DEV-%E8%A8%BB%E5%86%8A%E5%B8%B3%E8%99%9F/</url>
    <content><![CDATA[<h2 id="註冊帳號"><a href="#註冊帳號" class="headerlink" title="註冊帳號"></a>註冊帳號</h2><p>akasha dev-ui需要使用者註冊帳號，不同使用者可以獨自創建dataset、knowledge用來做文檔問答，也可以分享dataset、knowledge給其他使用者。</p>
<p><img src="https://hackmd.io/_uploads/rJtjE0eqT.png" alt="image"></p>
<p>點選右下角”Sign Up”進入註冊介面<br><img src="https://hackmd.io/_uploads/SygzS0gqa.png" alt="image"></p>
<p>註冊完成後便可使用Username 和 Password登入帳號<br><img src="https://hackmd.io/_uploads/SkTBSAg5p.png" alt="image"></p>
]]></content>
      <categories>
        <category>akasha-lab</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>FAST API</title>
    <url>/2024/12/26/FAST%20API/</url>
    <content><![CDATA[<h2 id="FAST-API"><a href="#FAST-API" class="headerlink" title="FAST API"></a>FAST API</h2><p>akasha 提供get_response, ask_self, ask_whole_file, get_summary的api server</p>
<h3 id="啟動"><a href="#啟動" class="headerlink" title="啟動"></a>啟動</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">akasha api (–port &#123;port&#125; –host &#123;host&#125; –workers &#123;num_of_workers&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">HOST = os.getenv(&quot;API_HOST&quot;, &quot;http://127.0.0.1&quot;)</span><br><span class="line">PORT = os.getenv(&quot;API_PORT&quot;, &quot;8000&quot;)</span><br><span class="line">urls = &#123;</span><br><span class="line">    &quot;summary&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/get_summary&quot;,</span><br><span class="line">    &quot;qa&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/get_response&quot;,</span><br><span class="line">    &quot;self&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/ask_self&quot;,</span><br><span class="line">    &quot;file&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/ask_whole_file&quot;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">openai_config = &#123;</span><br><span class="line">    &quot;azure_key&quot;: &#123;your api key&#125;,</span><br><span class="line">    &quot;azure_base&quot;: &#123;your api base&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">self_data = &#123;</span><br><span class="line">    &quot;prompt&quot;: &quot;太陽電池技術?&quot;,</span><br><span class="line">    &quot;info&quot;: &quot;太陽能電池技術5塊錢&quot;,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;max_doc_len&quot;: 1500,</span><br><span class="line">    &quot;temperature&quot;: 0.0,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">file_data = &#123;</span><br><span class="line">    &quot;doc_path&quot;: &quot;docs/mic/20230317_5軸工具機因應市場訴求改變的發展態勢.pdf&quot;,</span><br><span class="line">    &quot;prompt&quot;: &quot;五軸是什麼?&quot;,</span><br><span class="line">    &quot;chunk_size&quot;: 1000,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;embedding_model&quot;: &quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;max_doc_len&quot;: 1500,</span><br><span class="line">    &quot;temperature&quot;: 0.0,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">chat_data = &#123;</span><br><span class="line">    &quot;doc_path&quot;: &quot;docs/pns/&quot;,</span><br><span class="line">    &quot;prompt&quot;: &quot;太陽電池技術?&quot;,</span><br><span class="line">    &quot;chunk_size&quot;: 1000,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;embedding_model&quot;: &quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">    &quot;threshold&quot;: 0.1,</span><br><span class="line">    &quot;search_type&quot;: &#x27;auto&#x27;,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;max_doc_len&quot;: 1500,</span><br><span class="line">    &quot;temperature&quot;: 0.0,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line">summary_data = &#123;</span><br><span class="line">    &quot;file_path&quot;: &quot;docs/pns/2484.txt&quot;,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;summary_type&quot;: &quot;reduce_map&quot;,</span><br><span class="line">    &quot;summary_len&quot;: 500,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># chat_response = requests.post(urls[&quot;qa&quot;], json=chat_data).json()</span><br><span class="line"># print(chat_response)</span><br><span class="line"></span><br><span class="line"># sum_response = requests.post(</span><br><span class="line">#     urls[&quot;summary&quot;],</span><br><span class="line">#     json=summary_data,</span><br><span class="line"># ).json()</span><br><span class="line"></span><br><span class="line"># print(sum_response)</span><br><span class="line"></span><br><span class="line">self_response = requests.post(urls[&quot;self&quot;], json=self_data).json()</span><br><span class="line">print(self_response)</span><br><span class="line">file_response = requests.post(urls[&quot;file&quot;], json=file_data).json()</span><br><span class="line">print(file_response)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>ask_agent</title>
    <url>/2024/12/29/ask_agent/</url>
    <content><![CDATA[<h2 id="ask-agent"><a href="#ask-agent" class="headerlink" title="ask_agent"></a>ask_agent</h2><p>如果你想詢問較複雜的問題，使用ask_agent，語言模型會將你的問題拆解來提供較好的回答。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ak = akasha.Doc_QA(</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    chunk_size=<span class="number">500</span>,</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,</span><br><span class="line">)</span><br><span class="line">res = ak.ask_agent(</span><br><span class="line">    <span class="string">&quot;./docs/mic/&quot;</span>,     </span><br><span class="line">    <span class="string">&quot;LPWAN和5G的區別是什麼?&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LPWAN和5G的主要區別在於他們的頻寬、延遲、成本和應用場景。</span><br><span class="line"></span><br><span class="line">LPWAN的頻寬相對較低（0.3 KBps – 50KBps），延遲較高（秒 - 分），且成本較低。它的主要優點是低耗能、支援長距離傳輸，並且可以連接大量的設備。然而，由於其頻寬和延遲的限制，LPWAN在製造業中的</span><br><span class="line">應用主要適用於非即時、非關鍵性的應用，例如環境污染偵測、照明、人員移動等，且須長時間穩定使用的應用情境。</span><br><span class="line"></span><br><span class="line">相較之下，5G提供的頻寬範圍在1-10 Gbps，而延遲則在1-10 ms之間，成本較高。這使得5G非常適合需要高時序精密度的應用，例如異質設備協作、遠端操控、混合現實（MR）巡檢維修等。此外，5G網路在大型</span><br><span class="line">廠區中，相較於Wi-Fi，無移交控制（Handover）中斷問題，因此更適合如低延遲、快速移動型的自主移動機器人（AMR）或無人機（Drone）廣域應用。然而，5G私網的建置成本相對昂貴，可能會影響企業的導 </span><br><span class="line">入意願。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>文檔問答</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>XML格式</title>
    <url>/2024/12/25/XML%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="XML-Formatter"><a href="#XML-Formatter" class="headerlink" title="XML Formatter"></a>XML Formatter</h2><p>如果你想讓語言模型的回答為XML格式，可以使用XMLformatter</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><p>如以下範例，首先先定義你想要回傳的key值的名稱、說明和型別，並利用<em><strong>XML_formatter</strong></em>轉換成xml格式的prompt，並在問問題時把xml_prompt丟入system_prompt中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha.prompts as prompts</span><br><span class="line">import akasha</span><br><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">formatter = [</span><br><span class="line">        prompts.OutputSchema(name=&quot;學歷&quot;, description=&quot;受試者的就讀大學&quot;, type=&quot;str&quot;),</span><br><span class="line">        prompts.OutputSchema(name=&quot;經驗&quot;, description=&quot;受試者的工作經驗&quot;, type=&quot;str&quot;),</span><br><span class="line">        prompts.OutputSchema(name=&quot;專長&quot;, description=&quot;受試者的專長能力&quot;, type=&quot;list&quot;),</span><br><span class="line">        prompts.OutputSchema(name=&quot;年資&quot;, description=&quot;受試者的總工作年數&quot;, type=&quot;int&quot;)</span><br><span class="line">    ]</span><br><span class="line">xml_prompt = prompts.XML_formatter(formatter)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(topK=10, threshold=0.0)</span><br><span class="line"></span><br><span class="line">response = ak.ask_whole_file(file_path=&quot;docs/resume_pool/A.docx&quot;,</span><br><span class="line">system_prompt=xml_prompt, prompt=f&#x27;&#x27;&#x27;以上是受試者的履歷，請回答該受試者的學歷、經驗、專長、年資&#x27;&#x27;&#x27;)</span><br><span class="line"></span><br><span class="line">print(response)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;resume&gt;</span><br><span class="line">    &lt;學歷&gt;國立臺北科技大學電資學士班 四技 就學中&lt;/學歷&gt;</span><br><span class="line">    &lt;經驗&gt;英文短期文理補習班補習班導師／管理人員&lt;/經驗&gt;</span><br><span class="line">    &lt;專長&gt;</span><br><span class="line">        &lt;能力&gt;語言能力&lt;/能力&gt;</span><br><span class="line">        &lt;英文&gt;聽-中等, 說-中等, 讀-中等, 寫-中等&lt;/英文&gt;</span><br><span class="line">        &lt;證照&gt;TOEIC &lt;/證照&gt;</span><br><span class="line">    &lt;/專長&gt;</span><br><span class="line">    &lt;年資&gt;0-1&lt;/年資&gt;</span><br><span class="line">&lt;/resume&gt;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>指定輸出格式</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>ask_image</title>
    <url>/2024/12/29/ask_image/</url>
    <content><![CDATA[<h2 id="ask-image"><a href="#ask-image" class="headerlink" title="ask_image"></a>ask_image</h2><p>如果你想同時輸入圖片與文字來詢問多模態模型(如gpt-4o, llama3.2-Vision)，可以使用ask_image，圖片路徑image_path可以是網址或本地圖片路徑，模型類別目前支援 <em><strong>openai</strong></em>, <em><strong>remote</strong></em>(vllm), <em><strong>huggingface</strong></em>(llama3.2-Vision)，但huggingface目前不支援stream流輸出。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ak = akasha.Doc_QA(model=<span class="string">&quot;openai:gpt-4o&quot;</span>,)</span><br><span class="line">url = <span class="string">&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg&quot;</span></span><br><span class="line">png = <span class="string">&quot;../miao.png&quot;</span></span><br><span class="line"></span><br><span class="line">res = ak.ask_image(image_path=url, prompt = <span class="string">&quot;這張圖片是甚麼?&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">這張圖片顯示了一個長度不等的木板路，穿過一片綠色的草地和樹林。路面上有許多細小的草根和葉子。路面兩側是高約1米左右的青綠色野生植物，中間有一些紅色的灌木丛。天空是藍色的，有一</span><br><span class="line">些白雲。</span><br><span class="line"></span><br><span class="line">這張圖像可能是一個自然景觀或一個旅遊目的地，例如一個國家公園或一個鳥類保護區。它也可能是一個攝影作品，用來展示自然美景和人們與環境之間的互動關係。</span><br><span class="line"></span><br><span class="line">總體而言，這張圖像展現了人們與自然環境之間美麗而微妙的關係，並呼籲我們去探索、欣賞和保護我們周圍的世界。這張圖片顯示了一個長度不等的木板路，穿過一片綠色的草地和樹林。路面上有許多細小的草根和葉子。路面兩側是高約1米左右的青綠色野生植物，中間有一些紅色的灌木叢。天空是藍色的，有一些白雲。</span><br><span class="line"></span><br><span class="line">這張圖像可能是一個自然景觀或一個旅遊目的地，例如一個國家公園或一個鳥類保護區。它也可能是一個攝影作品，用來展示自然美景和人們與環境之間的互動關係。</span><br><span class="line"></span><br><span class="line">總體而言，這張圖像展現了人們與自然環境之間美麗而微妙的關係，並呼籲我們去探索、欣賞和保護我們周圍的世界。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>文檔問答</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>ask_self</title>
    <url>/2024/12/29/ask_self/</url>
    <content><![CDATA[<h2 id="ask-self"><a href="#ask-self" class="headerlink" title="ask_self"></a>ask_self</h2><p>如果你不想使用文件檔案，希望直接輸入文件內容，你可以使用ask_self，使用<em><strong>info</strong></em> 參數將文件的內容傳給語言模型，<em><strong>info</strong></em>參數可為<em><strong>str</strong></em> 或者 <em><strong>list of str</strong></em>。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">install_requires = [</span><br><span class="line">    &quot;pypdf&quot;,</span><br><span class="line">    &quot;langchain&gt;=0.1.0&quot;,</span><br><span class="line">    &quot;chromadb==0.4.14&quot;,</span><br><span class="line">    &quot;openai==0.27&quot;,</span><br><span class="line">    &quot;tiktoken&quot;,</span><br><span class="line">    &quot;lark==1.1.7&quot;,</span><br><span class="line">    &quot;scikit-learn&lt;1.3.0&quot;,</span><br><span class="line">    &quot;jieba==0.42.1&quot;,</span><br><span class="line">    &quot;sentence-transformers==2.2.2&quot;,</span><br><span class="line">    &quot;torch==2.0.1&quot;,</span><br><span class="line">    &quot;transformers&gt;=4.33.4&quot;, </span><br><span class="line">    &quot;llama-cpp-python==0.2.6&quot;,</span><br><span class="line">    &quot;auto-gptq==0.3.1&quot;,</span><br><span class="line">    &quot;tqdm==4.65.0&quot;,</span><br><span class="line">    &quot;docx2txt==0.8&quot;,</span><br><span class="line">    &quot;rouge==1.0.1&quot;,</span><br><span class="line">    &quot;rouge-chinese==1.0.3&quot;,</span><br><span class="line">    &quot;bert-score==0.3.13&quot;,</span><br><span class="line">    &quot;click&quot;,</span><br><span class="line">    &quot;tokenizers&gt;=0.13.3&quot;,</span><br><span class="line">    &quot;streamlit==1.28.2&quot;,</span><br><span class="line">    &quot;streamlit_option_menu==0.3.6&quot;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(</span><br><span class="line">    verbose=True,</span><br><span class="line">    max_doc_len=15000,</span><br><span class="line">    model=&quot;openai:gpt-4&quot;,</span><br><span class="line">)</span><br><span class="line">response = ak.ask_self(prompt=&quot;langchain的套件版本?&quot;, info=install_requires)</span><br></pre></td></tr></table></figure>


<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">langchain的套件版本是0.1.0或更高版本。</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>文檔問答</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>ask_whole_file</title>
    <url>/2024/12/29/ask_whole_file/</url>
    <content><![CDATA[<h2 id="ask-whole-file"><a href="#ask-whole-file" class="headerlink" title="ask_whole_file"></a>ask_whole_file</h2><p>如果你想詢問單個檔案的內容，且該文件檔不長，在語言模型的窗口大小內，你可以使用ask_whole_file將整個文件的內容給語言模型做為參考。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(</span><br><span class="line">    search_type=&quot;merge&quot;,</span><br><span class="line">    verbose=True,</span><br><span class="line">    max_doc_len=15000,</span><br><span class="line">    model=&quot;openai:gpt-4-32k&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = ak.ask_whole_file(system_prompt=&quot;用列舉的方式描述&quot;,</span><br><span class="line">    file_path=&quot;docs/mic/20230726_工業4_0發展重點與案例分析，以西門子、鴻海為例.pdf&quot;,</span><br><span class="line">    prompt=&quot;工業4.0有什麼可以參考的標準或是架構嗎?&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">工業4.0的參考標準或架構主要有以下幾種：</span><br><span class="line"></span><br><span class="line">1. 「工業 4.0成熟度指數」：由德國國家工程院（Acatech）提出，將發展階段劃分為電腦化、可連結、可視化、可分析、可預測、自適應共六個成熟度，前項為後項發展基礎。</span><br><span class="line"></span><br><span class="line">2. 「新加坡工業智慧指數」（Singapore Smart Industry Readiness Index, SIRI）：由新加坡政府提出，用於評估企業在工業4.0的發展程度。</span><br><span class="line"></span><br><span class="line">3. 「工業 4.0實施步驟方法論」：這是一種實施工業4.0的具體步驟，包括盤點公司內部待改善問題，分析現況與預期目標差異，以及規劃具體要改善的業務流程路線圖。</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>文檔問答</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>akashalab-Consult</title>
    <url>/2024/01/01/DEV-Consult/</url>
    <content><![CDATA[<h2 id="Chat"><a href="#Chat" class="headerlink" title="Chat"></a>Chat</h2><p>Chat與Regular Consult相似，會根據提供的文檔進行問答，但同時Chat也會記住使用者之前的問答互動，方便使用者進行追問。</p>
<p><img src="https://hackmd.io/_uploads/HJYO5ZfzR.png" alt="image"></p>
<p>若要進行與之前不相關、新的提問，可以點選右邊按紐Clear History清除紀錄。</p>
</br>
</br>


<h2 id="Regular-Consult"><a href="#Regular-Consult" class="headerlink" title="Regular Consult"></a>Regular Consult</h2><p>創建完Knowledge後，便可以利用它來做文檔問答，來到Consult頁面，選擇Knowledge後，便可以輸入問題，按下crtl+Enter後便可以提交問題給語言模型等待回應。</p>
<p><img src="https://hackmd.io/_uploads/HyLhLJZ9a.png" alt="image"></p>
<h3 id="更改參數"><a href="#更改參數" class="headerlink" title="更改參數"></a>更改參數</h3><p>若你為該Knowledge的擁有者，按下Advanced可以更改Knowledge的參數，提交問題後，參數將會儲存到config中。<br><img src="https://hackmd.io/_uploads/Hk4sPkb9p.png" alt="image"></p>
<h5 id="1-System-Prompt-為希望語言模型回答的格式"><a href="#1-System-Prompt-為希望語言模型回答的格式" class="headerlink" title="1. System Prompt 為希望語言模型回答的格式"></a>1. System Prompt 為希望語言模型回答的格式</h5><h5 id="2-language-model-為使用何種語言模型"><a href="#2-language-model-為使用何種語言模型" class="headerlink" title="2. language model 為使用何種語言模型"></a>2. language model 為使用何種語言模型</h5><h5 id="3-search-type-為搜尋文檔的方法"><a href="#3-search-type-為搜尋文檔的方法" class="headerlink" title="3. search type 為搜尋文檔的方法"></a>3. search type 為搜尋文檔的方法</h5><h5 id="4-Top-K-為使用文檔段落的數量"><a href="#4-Top-K-為使用文檔段落的數量" class="headerlink" title="4. Top K 為使用文檔段落的數量"></a>4. Top K 為使用文檔段落的數量</h5><h5 id="5-Threshold-為文檔與問題相似度的閾值"><a href="#5-Threshold-為文檔與問題相似度的閾值" class="headerlink" title="5. Threshold 為文檔與問題相似度的閾值"></a>5. Threshold 為文檔與問題相似度的閾值</h5><h5 id="6-Max-Doc-Length-為文檔段落的最長總長度"><a href="#6-Max-Doc-Length-為文檔段落的最長總長度" class="headerlink" title="6. Max Doc Length 為文檔段落的最長總長度"></a>6. Max Doc Length 為文檔段落的最長總長度</h5><h5 id="7-Temperature-為語言模型的隨機性"><a href="#7-Temperature-為語言模型的隨機性" class="headerlink" title="7. Temperature 為語言模型的隨機性"></a>7. Temperature 為語言模型的隨機性</h5></br>
</br>

<h2 id="Deep-Consult"><a href="#Deep-Consult" class="headerlink" title="Deep Consult"></a>Deep Consult</h2><p>若要詢問較為複雜的問題，可使用Deep-Consult，將可能需要的知識點做為子問題放到Sub-Questions中，再將最終期望詢問的問題填入Question欄位，按下”Submit”按鈕，便可等待語言模型回答。</p>
<p><img src="https://hackmd.io/_uploads/r1jk31Wqp.png" alt="image"></p>
</br>
</br>

<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>在Summary頁面，可以從Dataset中選擇一個文件檔案，並輸入指示進行摘要。</p>
<p><img src="https://hackmd.io/_uploads/ryP6Hht2a.png" alt="image"></p>
</br>
</br>


<p>你也可以上傳一個文件檔案進行摘要</p>
<p><img src="https://hackmd.io/_uploads/r1kcr2Knp.png" alt="image"></p>
]]></content>
      <categories>
        <category>akasha-lab</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>chain_of_thought</title>
    <url>/2024/12/29/chain_of_thought/</url>
    <content><![CDATA[<h2 id="使用chain-of-thought處理複雜的問題"><a href="#使用chain-of-thought處理複雜的問題" class="headerlink" title="使用chain_of_thought處理複雜的問題"></a>使用chain_of_thought處理複雜的問題</h2><p>如果你想詢問的問題較為複雜，可以將它拆解成一連串的小問題並使用chain_of_thought詢問。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your openAI key&quot;</span><br><span class="line"></span><br><span class="line">dir_path = &quot;mic/&quot;</span><br><span class="line">queries2 = [&quot;西門子自有工廠如何朝工業4.0 發展&quot;,&quot;詳細解釋「工業4.0 成熟度指數」發展路徑的六個成熟度&quot;,&quot;根據西門子自有工廠朝工業4.0發展，探討其各項工業4.0的成熟度指標&quot;]</span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">response = ak.chain_of_thought(dir_path, queries2, search_type=&#x27;svm&#x27;)</span><br><span class="line">print(response)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">response 1:</span><br><span class="line">西門子自有工廠朝工業4.0發展的方式包括以下幾個方面：</span><br><span class="line"></span><br><span class="line">1. 數位化戰略：西門子提出數位化戰略，從工業4.0策略擬定到落地執行，為客戶提供一條龍服務。他們設計數位工廠原型</span><br><span class="line">，搭配OT、IT方案，並使用西門子的MindSphere工業物聯網平台，發展數據可視化和數據分析相關應用。</span><br><span class="line"></span><br><span class="line">2. 跨領域合作：西門子近年積極與雲服務商、系統商等跨領域合作，推動智慧製造解決方案。此外，他們也與SAP進行ERP整合，專注於物聯網領域。</span><br><span class="line"></span><br><span class="line">3. 虛實整合：西門子在中國大陸成都生產研發基地的案例中，從研發、生產、訂單管理、供應商管理到物流作業</span><br><span class="line">，實現了整條價值鏈的虛實整合。他們不斷提高配料、傳輸、檢測等流程的自動化程度。</span><br><span class="line"></span><br><span class="line">總體而言，西門子通過數位化戰略、跨領域合作和虛實整合等方式，推動自有工廠朝工業4.0發 </span><br><span class="line">展。他們致力於提升生產效率和效能，並利用先進的技術和解決方案實現智慧工廠的建設。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response 2:</span><br><span class="line">「工業4.0成熟度指數」的發展路徑劃分為六個成熟度，分別是電腦化、可連結、可視化、可分析、可預測和自適應。</span><br><span class="line"></span><br><span class="line">1. 電腦化：這是工業4.0發展的起點，指企業開始使用計算機技</span><br><span class="line">術，人員不再手動操作機械。然而，機械仍未聯網，各個IT系統仍各自獨立，資料尚未串聯。例如，企業的ERP系統與生產相關的系統獨立運作，訂單與產品品檢紀錄分散於兩套系統，導致 </span><br><span class="line">訂單無法回溯出現品質問題的環節。</span><br><span class="line"></span><br><span class="line">2. 可連結：在這個成熟度階段，企業開始將各個IT系統進行連接，實現資料的串聯。這使得不同系統之間可以共享資料，提高資訊的流通效率。例 </span><br><span class="line">如，企業的ERP系統與生產相關的系統進行連接，訂單與產品品檢紀錄可以實現資料的回溯。</span><br><span class="line"></span><br><span class="line">3. 可視化：在這個成熟度階段，企業開始實現資料的可視化，將資料以圖形化或圖表化的方</span><br><span class="line">式呈現，使得管理者可以直觀地了解企業的運營狀況。例如，企業可以使用數據儀表板或報表來呈現生產線的運行情況和產品的品質指標。</span><br><span class="line"></span><br><span class="line">4. 可分析：在這個成熟度階段，企業開始進 </span><br><span class="line">行資料的分析，利用數據分析工具和算法來挖掘資料中的價值和洞察。這使得企業可以更深入地了解生產過程中的問題和潛在的改進空間。例如，企業可以使用數據分析工具來分析生產線的</span><br><span class="line">效率和品質問題，並提出改進措施。</span><br><span class="line"></span><br><span class="line">5. 可預測：在這個成熟度階段，企業開始利用資料分析的結果來進行預測和預測模型的建立。這使得企業可以預測生產過程中可能出現的問題，並 </span><br><span class="line">提前採取相應的措施。例如，企業可以利用預測模型來預測生產線的故障和產品的品質問題，並提前進行維護和調整。</span><br><span class="line"></span><br><span class="line">6. 自適應：在這個成熟度階段，企業開始實現自動化和自適應能 </span><br><span class="line">力，使得生產過程可以根據實時的數據和環境變化進行調整和優化。這使得企業可以更靈活地應對市場需求和生產變化。例如，企業可以實現生產線的自動調整和產品的自動優化，以適應市</span><br><span class="line">場需求的變化。</span><br><span class="line"></span><br><span class="line">這六個成熟度階段代表了企業在工業4.0發展過程中的不同階段和能力水平，企業可以根據自身的情況和目標，逐步提升成熟度，實現工業4.0的目標。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response 3:</span><br><span class="line">根據西門子自有工廠朝工業4.0發展的方式，可以探討其在工業4.0成熟度指標中的幾個方面：</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">1. 數位化戰略：西門子提出數位化戰略，從工業4.0策略擬定到落地執行提供一條龍服務</span><br><span class="line">。這代表企業在工業4.0成熟度指標中已經達到了可連結和可視化的階段，並開始將數據應用於生產優化和資源利用。</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">2. 整合系統：西門子在廠內進行軟體間整合，包括PLM、ERP、MOM </span><br><span class="line">、WMS和Automation五大系統的整合，使數據互聯互通。這代表企業在工業4.0成熟度指標中已經達到了可分析和可預測的階段，並能夠利用數據分析技術進行深入分析和預測。</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">3. 數據 應用：西門子利用自有的數位雙生軟體Tecnomatix，打造虛擬工廠，模擬生產狀況或監控實際生產狀況。這代表企業在工業4.0成熟度指標中已經達到了可分析和可預測的階段，並能夠利用 </span><br><span class="line">數據應用提供的資訊，優化生產設備和工序。</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">總的來說，根據西門子自有工廠朝工業4.0發展的方式，可以看出他們在工業4.0成熟度指標中已經達到了可連結、可視化、可分析和可預測，優化生產設備和工序。</span><br></pre></td></tr></table></figure>





</br>
</br>
</br>
</br>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### Arguments of Doc_QA class ###</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Args:</span><br><span class="line">            **embeddings (str, optional)**: the embeddings used in query and vector storage. Defaults to &quot;text-embedding-ada-002&quot;.\n</span><br><span class="line">            **chunk_size (int, optional)**: chunk size of texts from documents. Defaults to 1000.\n</span><br><span class="line">            **model (str, optional)**: llm model to use. Defaults to &quot;gpt-3.5-turbo&quot;.\n</span><br><span class="line">            **verbose (bool, optional)**: show log texts or not. Defaults to False.\n</span><br><span class="line">            **threshold (float, optional)**: the similarity threshold of searching. Defaults to 0.2.\n</span><br><span class="line">            **language (str, optional)**: the language of documents and prompt, use to make sure docs won&#x27;t exceed</span><br><span class="line">                max token size of llm input.\n</span><br><span class="line">            **search_type (str, optional)**: search type to find similar documents from db, default &#x27;merge&#x27;.</span><br><span class="line">                includes &#x27;merge&#x27;, &#x27;mmr&#x27;, &#x27;svm&#x27;, &#x27;tfidf&#x27;, also, you can custom your own search_type function, as long as your</span><br><span class="line">                function input is (query_embeds:np.array, docs_embeds:list[np.array], k:int, relevancy_threshold:float, log:dict) </span><br><span class="line">                and output is a list [index of selected documents].\n</span><br><span class="line">            **record_exp (str, optional)**: use aiido to save running params and metrics to the remote mlflow or not if record_exp not empty, and set record_exp as experiment name.  default &quot;&quot;.\n</span><br><span class="line">            **system_prompt (str, optional)**: the system prompt that you assign special instruction to llm model, so will not be used</span><br><span class="line">                in searching relevant documents. Defaults to &quot;&quot;.\n</span><br><span class="line">            **max_doc_len (int, optional)**: max document size of llm input. Defaults to 1500.\n</span><br><span class="line">            **temperature (float, optional)**: temperature of llm model from 0.0 to 1.0 . Defaults to 0.0.\n</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>文檔問答</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>JSON格式</title>
    <url>/2024/12/25/JSON%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="JSON-Formatter"><a href="#JSON-Formatter" class="headerlink" title="JSON Formatter"></a>JSON Formatter</h2><p>如果你想讓語言模型的回答為JSON格式，可以使用JSONformatter</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><p>如以下範例，首先先定義你想要回傳的key值的名稱、說明和型別，並利用<em><strong>JSON_formatter</strong></em>轉換成json格式的prompt，並在問問題時把JSON_prompt丟入system_prompt中。</p>
<p>如formatter2和formatter3，你也可以直接使用JSON_formatter_list或JSON_formatter_dict將list或dictionary轉換成json格式的prompt。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha.prompts as prompts</span><br><span class="line">import akasha</span><br><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">formatter = [</span><br><span class="line">        prompts.OutputSchema(name=&quot;學歷&quot;, description=&quot;受試者的就讀大學&quot;, type=&quot;str&quot;),</span><br><span class="line">        prompts.OutputSchema(name=&quot;經驗&quot;, description=&quot;受試者的工作經驗&quot;, type=&quot;str&quot;),</span><br><span class="line">        prompts.OutputSchema(name=&quot;專長&quot;, description=&quot;受試者的專長能力&quot;, type=&quot;list&quot;),</span><br><span class="line">        prompts.OutputSchema(name=&quot;年資&quot;, description=&quot;受試者的總工作年數&quot;, type=&quot;int&quot;)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">formatter2 = prompts.JSON_formatter_list(names=[&quot;學歷&quot;,&quot;經驗&quot;,&quot;專長&quot;,&quot;年資&quot;], types=[&quot;str&quot;,&quot;str&quot;,&quot;list&quot;,&quot;int&quot;],\</span><br><span class="line">        descriptions=[&quot;受試者的就讀大學&quot;,&quot;受試者的工作經驗&quot;,&quot;受試者的專長能力&quot;,&quot;受試者的總工作年數&quot;])</span><br><span class="line"></span><br><span class="line">formatter3 = prompts.JSON_formatter_dict([&#123; &quot;name&quot;: &quot;學歷&quot;, &quot;description&quot;: &quot;受試者的就讀大學&quot;, &quot;type&quot;: &quot;str&quot; &#125;,\</span><br><span class="line">        &#123; &quot;name&quot;: &quot;經驗&quot;, &quot;description&quot;: &quot;受試者的工作經驗&quot;, &quot;type&quot;: &quot;str&quot; &#125;,\</span><br><span class="line">            &#123; &quot;name&quot;: &quot;專長&quot;, &quot;description&quot;: &quot;受試者的專長能力&quot;, &quot;type&quot;: &quot;list&quot; &#125;,\</span><br><span class="line">                &#123; &quot;name&quot;: &quot;年資&quot;, &quot;description&quot;: &quot;受試者的總工作年數&quot;, &quot;type&quot;: &quot;int&quot; &#125;])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">JSON_prompt = prompts.JSON_formatter(formatter)</span><br><span class="line"># JSON_prompt = prompts.JSON_formatter(formatter2)</span><br><span class="line"># JSON_prompt = prompts.JSON_formatter(formatter3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(topK=10, threshold=0.0)</span><br><span class="line"></span><br><span class="line">response = ak.ask_whole_file(file_path=&quot;docs/resume_pool/A.docx&quot;,</span><br><span class="line">system_prompt=JSON_prompt, prompt=f&#x27;&#x27;&#x27;以上是受試者的履歷，請回答該受試者的學歷、經驗、專長、年資&#x27;&#x27;&#x27;)</span><br><span class="line"></span><br><span class="line">parse_json = akasha.helper.extract_json(resposne)</span><br><span class="line"></span><br><span class="line">print(parse_json)</span><br><span class="line">print(type(parse_json))</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;學歷&#x27;: &#x27;國立臺北科技大學電資學士班 四技&#x27;, &#x27;經驗&#x27;: &#x27;總年資0-1年年工作經歷&#x27;, &#x27;專長&#x27;: [&#x27;計算機網路(協定)&#x27;, &#x27;資料庫系統&#x27;, &#x27;物件導向程式設計&#x27;, &#x27;C語言&#x27;, &#x27;python&#x27;, &#x27;C++&#x27;, &#x27;Gitlab&#x27;, &#x27;Jenkins&#x27;, &#x27;Git&#x27;, &#x27;linux&#x27;, &#x27;Google表單&#x27;], &#x27;年資&#x27;: 1&#125; </span><br><span class="line"></span><br><span class="line">&lt;class &#x27;dict&#x27;&gt;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>指定輸出格式</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>get_response</title>
    <url>/2024/12/29/get_response/</url>
    <content><![CDATA[<h2 id="get-response"><a href="#get-response" class="headerlink" title="get_response"></a>get_response</h2><p>使用者輸入一個或多個文件(.pdf, .docx, .txt)資料夾，此函數可以讓語言模型根據搜尋到的文件回答問題。藉由使用者的問題和文件庫搜尋到知識片段，可以不用將整份文件輸入給模型，就讓語言模型正確回答問題。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">qa = akasha.Doc_QA(</span><br><span class="line">    verbose=False, </span><br><span class="line">    search_type=&quot;svm&quot;, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line"></span><br><span class="line">qa.get_response(</span><br><span class="line">        doc_path=&quot;docs/mic/&quot;,</span><br><span class="line">        prompt=&quot;五軸是甚麼?&quot;,</span><br><span class="line">        chunk_size=500,</span><br><span class="line">        max_doc_len=1500,</span><br><span class="line">        system_prompt=&quot;請用中文回答&quot;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">五軸工具機是一種先進的加工裝置，透過2軸控制工具旋轉方向，再透過長寬高3軸移動進行切削加工。相較於工具方向不會改變的3軸工具機，五軸工具機能夠進行更加複雜形狀的加工，並且具有更高</span><br><span class="line">的加工精密度和自動化能力。</span><br></pre></td></tr></table></figure>


<h3 id="stream輸出"><a href="#stream輸出" class="headerlink" title="stream輸出"></a>stream輸出</h3><p>若需要即時輸出的場合(如UI即時顯示回答)，使用stream&#x3D;True可使get_response回傳generator。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">qa = akasha.Doc_QA(</span><br><span class="line">    verbose=False, </span><br><span class="line">    search_type=&quot;svm&quot;, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;, </span><br><span class="line">    stream=True)</span><br><span class="line"></span><br><span class="line">streaming = qa.get_response(</span><br><span class="line">        doc_path=&quot;docs/mic/&quot;,</span><br><span class="line">        prompt=&quot;五軸是甚麼?&quot;,</span><br><span class="line">    hitstory_messages=[&quot;hi 我的名字是iii&quot;, &quot;你好iii&quot;],</span><br><span class="line">        system_prompt=&quot;請用中文回答&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">for s in streaming:</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>


<h3 id="dbs物件"><a href="#dbs物件" class="headerlink" title="dbs物件"></a>dbs物件</h3><p>如想對同個文件集做多次問答，可以先建立dbs物件並傳入，避免多次重複載入文件的chromadb</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">db_files = akasha.createDB_file(file_path = [&quot;f1.txt&quot;,&quot;f2.docs&quot;], embeddings=&quot;openai:text-embedding-ada-002&quot;,chunk_size=500, ignore_check=True)</span><br><span class="line">db_directory = akasha.createDB_directory(doc_path= &quot;./docs/mic/&quot;, </span><br><span class="line">embeddings=&quot;openai:text-embedding-ada-002&quot;, ignore_check=True)</span><br><span class="line">qa = akasha.Doc_QA(</span><br><span class="line">    verbose=True, </span><br><span class="line">    search_type=&quot;svm&quot;, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;, </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">qa.get_response(</span><br><span class="line">        doc_path=db_directory,</span><br><span class="line">        prompt=&quot;五軸是甚麼?&quot;,</span><br><span class="line">        system_prompt=&quot;請用中文回答&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h3 id="Doc-QA-參數"><a href="#Doc-QA-參數" class="headerlink" title="Doc_QA 參數"></a>Doc_QA 參數</h3><h5 id="verbose-如果設True，會顯示每個步驟產生的文字和狀態"><a href="#verbose-如果設True，會顯示每個步驟產生的文字和狀態" class="headerlink" title="verbose: 如果設True，會顯示每個步驟產生的文字和狀態"></a>verbose: 如果設True，會顯示每個步驟產生的文字和狀態</h5><h5 id="search-type-用來搜尋文件段落的方法，可選擇-svm-tfidf-merge-mmr-knn"><a href="#search-type-用來搜尋文件段落的方法，可選擇-svm-tfidf-merge-mmr-knn" class="headerlink" title="search_type: 用來搜尋文件段落的方法，可選擇: svm, tfidf, merge, mmr, knn."></a>search_type: 用來搜尋文件段落的方法，可選擇: <em><strong>svm</strong></em>, <em><strong>tfidf</strong></em>, <em><strong>merge</strong></em>, <em><strong>mmr</strong></em>, <em><strong>knn</strong></em>.</h5><h5 id="model-使用的語言模型，如-openai-gpt-3-5-turbo-hf-meta-llama-Llama-2-13b-chat-hf"><a href="#model-使用的語言模型，如-openai-gpt-3-5-turbo-hf-meta-llama-Llama-2-13b-chat-hf" class="headerlink" title="model: 使用的語言模型，如 openai:gpt-3.5-turbo, hf:meta-llama&#x2F;Llama-2-13b-chat-hf"></a>model: 使用的語言模型，如 <em><strong>openai:gpt-3.5-turbo</strong></em>, <em><strong>hf:meta-llama&#x2F;Llama-2-13b-chat-hf</strong></em></h5><h5 id="doc-path-一個或多個包含文件檔案的資料夾路徑名稱"><a href="#doc-path-一個或多個包含文件檔案的資料夾路徑名稱" class="headerlink" title="doc_path: 一個或多個包含文件檔案的資料夾路徑名稱"></a>doc_path: 一個或多個包含文件檔案的資料夾路徑名稱</h5><h5 id="prompt-使用者的問題"><a href="#prompt-使用者的問題" class="headerlink" title="prompt: 使用者的問題"></a>prompt: 使用者的問題</h5><h5 id="max-doc-len-最長可允許的文件段落總長度"><a href="#max-doc-len-最長可允許的文件段落總長度" class="headerlink" title="max_doc_len: 最長可允許的文件段落總長度"></a>max_doc_len: 最長可允許的文件段落總長度</h5><h5 id="chunk-size-單個文件段落的長度"><a href="#chunk-size-單個文件段落的長度" class="headerlink" title="chunk_size: 單個文件段落的長度"></a>chunk_size: 單個文件段落的長度</h5><h5 id="system-prompt-指示給語言模型的output格式需求"><a href="#system-prompt-指示給語言模型的output格式需求" class="headerlink" title="system_prompt: 指示給語言模型的output格式需求"></a>system_prompt: 指示給語言模型的output格式需求</h5><h4 id="stream-如果設為True，會回傳generator"><a href="#stream-如果設為True，會回傳generator" class="headerlink" title="stream: 如果設為True，會回傳generator"></a>stream: 如果設為True，會回傳generator</h4><h4 id="history-messages-需要一併提供給語言模型的對話紀錄"><a href="#history-messages-需要一併提供給語言模型的對話紀錄" class="headerlink" title="history_messages: 需要一併提供給語言模型的對話紀錄"></a>history_messages: 需要一併提供給語言模型的對話紀錄</h4>]]></content>
      <categories>
        <category>文檔問答</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>image</title>
    <url>/2024/01/28/image/</url>
    <content><![CDATA[<h1 id="新版-DevSecOps-的-GitLab-Repository-存取說明"><a href="#新版-DevSecOps-的-GitLab-Repository-存取說明" class="headerlink" title="新版 DevSecOps 的 GitLab Repository 存取說明"></a>新版 DevSecOps 的 GitLab Repository 存取說明</h1><h2 id="1-設置-Token"><a href="#1-設置-Token" class="headerlink" title="1. 設置 Token"></a>1. 設置 Token</h2><ul>
<li>在<code>DevSecOps</code>平台中選擇專案，連到<code>GitLab</code>專案頁面。然後選取<code>Settings</code>中的<code>Access Token</code>選項</li>
</ul>
<p><img src="https://hackmd.io/_uploads/BJXGKF79a.png" alt="image"></p>
<ul>
<li>在<code>Project Access Tokens</code>頁面中填入各項資訊（如下圖）</li>
</ul>
<p><img src="https://hackmd.io/_uploads/rJwYjK7q6.png" alt="image"></p>
<ul>
<li>之後便可以取得此專案的<code>token</code>。<strong>請注意這個<code>token</code>之後就不會再出現，所以複製之後要自己保存好！</strong></li>
</ul>
<p><img src="https://hackmd.io/_uploads/rkNcatXqT.png" alt="image"></p>
<h2 id="2-在本機端複製專案"><a href="#2-在本機端複製專案" class="headerlink" title="2. 在本機端複製專案"></a>2. 在本機端複製專案</h2><p>在專案頁面點選<code>Clone</code>按鈕，並複製<code>https</code>的網址。</p>
<p><img src="https://hackmd.io/_uploads/SkHFk97ca.png" alt="image"></p>
<p>在本機端命令列中輸入下列指令，再依據提示要求輸入<code>username</code>與<code>token</code>。**(注意：這邊要輸入的不是<code>password</code>，而是<code>token</code>)**</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://gitlab-devops.iii.org.tw/iiidevops/&lt;project-name&gt;.git</span><br></pre></td></tr></table></figure>

<p>或是在<code>git clone</code>指令中加入<code>username</code>，之後會被要求輸入密碼，再輸入<code>token</code>即可。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://&lt;username&gt;@gitlab-devops.iii.org.tw/iiidevops/&lt;project-name&gt;.git</span><br></pre></td></tr></table></figure>

<p>或是在<code>git clone</code>指令中加入<code>username</code>與<code>token</code>:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://&lt;username&gt;:&lt;token&gt;@gitlab-devops.iii.org.tw/iiidevops/&lt;project-name&gt;.git</span><br></pre></td></tr></table></figure>








]]></content>
  </entry>
  <entry>
    <title>summary</title>
    <url>/2024/12/27/summary/</url>
    <content><![CDATA[<h2 id="文件摘要"><a href="#文件摘要" class="headerlink" title="文件摘要"></a>文件摘要</h2><p>若要創建文本文件的摘要（.pdf、.txt.、docx），您可以使用 <em><strong>summary.summarize_file</strong></em> 函數。如範例，以下使用 map_reduce 摘要方法指示語言模型生成大約 500 字的摘要。有兩種摘要類型，<em><strong>map_reduce</strong></em> 和 <em><strong>refine</strong></em>，<em><strong>map_reduce</strong></em> 將對每個文本段落進行摘要，然後使用所有摘要的文本段落生成最終摘要；<em><strong>refine</strong></em> 將逐個摘要每個文本段落，並使用前一個摘要作為摘要下一段的提示，以獲得更高水平的摘要一致性。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">sum = akasha.Summary( chunk_size=1000, chunk_overlap=100)</span><br><span class="line">sum.summarize_file(file_path=&quot;doc/mic/5軸工具機因應市場訴求改變的發展態勢.pdf&quot;,summary_type=&quot;map_reduce&quot;, summary_len=500\</span><br><span class="line">, chunk_overlap=40)</span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">### Arguments of Summary class ###</span><br><span class="line"> Args:</span><br><span class="line">            **chunk_size (int, optional)**: chunk size of texts from documents. Defaults to 1000.</span><br><span class="line">            **chunk_overlap (int, optional)**: chunk overlap of texts from documents. Defaults to 40.</span><br><span class="line">            **model (str, optional)**: llm model to use. Defaults to &quot;gpt-3.5-turbo&quot;.</span><br><span class="line">            **verbose (bool, optional)**: show log texts or not. Defaults to False.</span><br><span class="line">            **threshold (float, optional)**: the similarity threshold of searching. Defaults to 0.2.</span><br><span class="line">            **language (str, optional)**: the language of documents and prompt, use to make sure docs won&#x27;t exceed</span><br><span class="line">                max token size of llm input.</span><br><span class="line">            **record_exp (str, optional)**: use aiido to save running params and metrics to the remote mlflow or not if record_exp not empty, and setrecord_exp as experiment name.  default &quot;&quot;.</span><br><span class="line">            **system_prompt (str, optional)**: the system prompt that you assign special instruction to llm model, so will not be used</span><br><span class="line">                in searching relevant documents. Defaults to &quot;&quot;.</span><br><span class="line">            **max_doc_len(int, optional)**: max docuemnt length of llm input. Defaults to 1500.</span><br><span class="line">            **temperature (float, optional)**: temperature of llm model from 0.0 to 1.0 . Defaults to 0.0.</span><br><span class="line">            **auto_translate (bool, optional)**: translate summary into language or not.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>摘要</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>auto_create_questionset</title>
    <url>/2024/12/28/auto_create_questionset/</url>
    <content><![CDATA[<h2 id="自動產生問題"><a href="#自動產生問題" class="headerlink" title="自動產生問題"></a>自動產生問題</h2><p>如果您不想自己創建問題集來評估當前參數的性能，您可以使用 <em><strong>eval.auto_create_questionset</strong></em> 功能自動生成一個包含參考答案的問題集。隨後，您可以使用 <em><strong>eval.auto_evaluation</strong></em> 獲取評估指標，如 Bert_score、Rouge 和 LLM_score（對於問答問題集），以及單選問題集的正確率。這些分數範圍從 0 到 1，較高的值表示生成的回答與參考答案更接近。</p>
<p>如範例，以下創建了一個名為 ‘mic_essay.txt’ 的問題集文本文件，其中包含十個問題和參考答案。每個問題都是從 ‘doc&#x2F;mic&#x2F;‘ 目錄中給定文檔的內容段落中隨機生成的。然後，您可以使用該問題集文本文件來評估要測試的參數的性能。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(question_style=&quot;essay&quot;, search_type=&#x27;merge&#x27;,\</span><br><span class="line">      model=&quot;openai:gpt-3.5-turbo&quot;, embeddings=&quot;openai:text-embedding-ada-002&quot;,record_exp=&quot;exp_mic_auto_questionset&quot;)</span><br><span class="line"></span><br><span class="line">eva.auto_create_questionset(doc_path=&quot;doc/mic/&quot;, question_num=10, output_file_path=&quot;questionset/mic_essay.txt&quot;)</span><br><span class="line"></span><br><span class="line">bert_score, rouge, llm_score, tol_tokens = eva.auto_evaluation(questionset_file=&quot;questionset/mic_essay.txt&quot;, doc_path=&quot;doc/mic/&quot;, question_style = &quot;essay&quot;, record_exp=&quot;exp_mic_auto_evaluation&quot;,topK=3,search_type=&quot;svm&quot;)</span><br><span class="line">print(&quot;bert_score: &quot;, bert_score, &quot;\nrouge: &quot;, rouge, &quot;\nllm_score: &quot;, llm_score)</span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">bert_score: 0.782</span><br><span class="line">rouge: 0.81</span><br><span class="line">llm_score: 0.393</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="使用question-type測試不同方面的能力"><a href="#使用question-type測試不同方面的能力" class="headerlink" title="使用question_type測試不同方面的能力"></a>使用question_type測試不同方面的能力</h2><p>question_type 参数提供了四種問題類型：<em><strong>fact</strong></em>、<em><strong>summary</strong></em>、<em><strong>irrelevant</strong></em>、<em><strong>compared</strong></em>，預設是 fact。 </p>
<ol>
<li>fact測試回答一般事實的能力</li>
<li>summary測試模型做摘要的能力</li>
<li>irrelevant測試模型能否分辨文件中不存在答案的問題</li>
<li>compared測試模型比較不同事物的能力</li>
</ol>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(search_type=&#x27;merge&#x27;, question_type = &quot;irrelevant&quot;, model=&quot;openai:gpt-3.5-turbo&quot;, record_exp=&quot;exp_mic_auto_questionset&quot;)</span><br><span class="line"></span><br><span class="line">eva.auto_create_questionset(doc_path=&quot;doc/mic/&quot;, question_num=10, output_file_path=&quot;questionset/mic_irre.txt&quot;)</span><br><span class="line"></span><br><span class="line">bert_score, rouge, llm_score, tol_tokens = eva.auto_evaluation(questionset_file=&quot;questionset/mic_irre.txt&quot;, doc_path=&quot;doc/mic/&quot;, question_style = &quot;essay&quot;, record_exp=&quot;exp_mic_auto_evaluation&quot;,search_type=&quot;svm&quot;)</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="指定問題集主題"><a href="#指定問題集主題" class="headerlink" title="指定問題集主題"></a>指定問題集主題</h2><p>如果你想生成特定主題的問題，你可以使用 <em><strong>create_topic_questionset</strong></em> 函數，它會使用輸入的主題在文檔中找到相關的文件段落並生成問題集。</p>
<h3 id="範例-1"><a href="#範例-1" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(search_type=&#x27;merge&#x27;,question_type = &quot;irrelevant&quot;, model=&quot;openai:gpt-3.5-turbo&quot;, record_exp=&quot;exp_mic_auto_questionset&quot;)</span><br><span class="line"></span><br><span class="line">eva.create_topic_questionset(doc_path=&quot;doc/mic/&quot;, topic= &quot;工業4.0&quot;, question_num=3, output_file_path=&quot;questionset/mic_topic_irre.txt&quot;)</span><br><span class="line"></span><br><span class="line">bert_score, rouge, llm_score, tol_tokens = eva.auto_evaluation(questionset_file=&quot;questionset/mic_topic_irre.txt&quot;, doc_path=&quot;doc/mic/&quot;, question_style = &quot;essay&quot;, record_exp=&quot;exp_mic_auto_evaluation&quot;,search_type=&quot;svm&quot;)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>模型評估</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>ui設定</title>
    <url>/2024/12/24/ui%E8%A8%AD%E5%AE%9A/</url>
    <content><![CDATA[<h2 id="安裝"><a href="#安裝" class="headerlink" title="安裝"></a>安裝</h2><p>只要你安裝了akasha，便可以直接使用akasha_ui，在terminal執行:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha ui</span></span><br></pre></td></tr></table></figure>

<p>便可以在瀏覽器上<a href="http://localhost:8501/">開啟</a>，開始使用akasha ui</p>
</br>
</br>

<h2 id="上傳文件檔"><a href="#上傳文件檔" class="headerlink" title="上傳文件檔"></a>上傳文件檔</h2><p>上傳你需要的文件檔案，並取資料夾名稱，創立知識庫。<br>:::info<br>請注意文件檔只允許(.docx, .txt, .pdf)<br>:::<br><img src="https://hackmd.io/_uploads/B1glkq19a.png" alt="ui_upload"></p>
</br>
</br>

<h2 id="設定"><a href="#設定" class="headerlink" title="設定"></a>設定</h2><p>在設定頁面，可以選擇要詢問的知識庫和調整各種參數、選擇不同語言模型。<br>:::info<br>若使用openAI模型，請在左側輸入 openAI的key，azure openAI則需要額外輸入url。<br>:::<br><img src="https://hackmd.io/_uploads/BJ0TRYJcT.png" alt="ui_setting"></p>
<h2 id="手動增加模型"><a href="#手動增加模型" class="headerlink" title="手動增加模型"></a>手動增加模型</h2><p>如果你想使用不同的語言模型，可以至<a href="https://huggingface.co/">huggingface</a>下載模型到”&#x2F;model”資料夾，模型便會加至設定中</p>
<p><img src="https://hackmd.io/_uploads/SyS6g5yqa.png" alt="ui_model"></p>
<p>設定完成後，便可開始使用akasha ui</p>
]]></content>
      <categories>
        <category>UI</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>ui操作</title>
    <url>/2024/12/24/ui%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="get-response"><a href="#get-response" class="headerlink" title="get_response"></a>get_response</h2><p>確認設定中有選擇正確的知識庫後，在system_prompt中填入希望回答的格式，在prompt中填入問題，按下submit便可以執行文檔問答。<br><img src="https://hackmd.io/_uploads/BkmIZ9y5T.png" alt="ui_5"></p>
</br>
</br>


<p>可以使用<em><strong>clear</strong></em> 按鈕清空對話欄，也可以使用左側<em><strong>Download Log</strong></em>按鈕下載紀錄<br><img src="https://hackmd.io/_uploads/H1MgEckqT.png" alt="image"></p>
</br>
</br>

<h2 id="chain-of-thought"><a href="#chain-of-thought" class="headerlink" title="chain_of_thought"></a>chain_of_thought</h2><p>使用<em><strong>Add Prompt</strong></em> 按鈕增加子問題，便可以使用chain of thought先提問小問題並利用小問題的答案回答較為複雜的問題。<br><img src="https://hackmd.io/_uploads/HkEQG5kqa.png" alt="image"></p>
</br>
</br>


<h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p>選擇summary方法與長度後，上傳單一文件檔便可得到該文檔的摘要。<br><img src="https://hackmd.io/_uploads/r15wQ9y96.png" alt="image"></p>
]]></content>
      <categories>
        <category>UI</category>
      </categories>
      <tags>
        <tag>akasha-UI</tag>
      </tags>
  </entry>
  <entry>
    <title>optimum_combination</title>
    <url>/2024/12/28/optimum_combination/</url>
    <content><![CDATA[<h2 id="Find-Optimum-Combination"><a href="#Find-Optimum-Combination" class="headerlink" title="Find Optimum Combination"></a>Find Optimum Combination</h2><p>若要測試所有可用的組合並找到最佳參數，您可以使用 optimum_combination 函數。您可以提供不同的嵌入模型、文件段落大小、語言模型、文件搜索方法以及最相關文檔的數量（topK），該函數將測試所有組合以找到根據給定的問題集和文檔的最佳組合。請注意，最佳得分組合是最高正確率組合，而最佳性價比組合是需要最少token以獲得正確答案的組合。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line">import os</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv() </span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your openAI key&quot;</span><br><span class="line">os.environ[&quot;HF_TOKEN&quot;] = &quot;your huggingface key&quot;</span><br><span class="line">dir_path = &quot;doc/pvc/&quot;</span><br><span class="line">exp_name = &quot;exp_akasha_optimum_combination&quot;</span><br><span class="line">embeddings_list = [&quot;hf:shibing624/text2vec-base-chinese&quot;, &quot;openai:text-embedding-ada-002&quot;]</span><br><span class="line">model_list = [&quot;openai:gpt-3.5-turbo&quot;,&quot;hf:FlagAlpha/Llama2-Chinese-13b-Chat-4bit&quot;,&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;,\</span><br><span class="line">            &quot;llama-gpu:model/llama-2-7b-chat.Q5_K_S.gguf&quot;, &quot;llama-gpu:model/llama-2-13b-chat.Q5_K_S.gguf&quot;]</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(question_style=&quot;single_choice&quot;)</span><br><span class="line">eva.optimum_combination(&quot;question_pvc.txt&quot;, dir_path,  embeddings_list = embeddings_list, model_list = model_list,</span><br><span class="line">            chunk_size_list=[200, 400, 600], search_type_list=[&quot;merge&quot;,&quot;tfidf&quot;,],record_exp=exp_name)</span><br></pre></td></tr></table></figure>


<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">Best correct rate:  1.000</span><br><span class="line">Best score combination:  </span><br><span class="line"></span><br><span class="line">embeddings: openai:text-embedding-ada-002, chunk size: 400, model: openai:gpt-3.5-turbo, search type: merge</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">embeddings: openai:text-embedding-ada-002, chunk size: 400, model: openai:gpt-3.5-turbo, search type: tfidf</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">Best cost-effective:</span><br><span class="line"></span><br><span class="line">embeddings: hf:shibing624/text2vec-base-chinese, chunk size: 400, model: openai:gpt-3.5-turbo, search type: tfidf</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>模型評估</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>安裝&amp;使用</title>
    <url>/2024/12/30/%E5%AE%89%E8%A3%9D&amp;%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="安裝WSL"><a href="#安裝WSL" class="headerlink" title="安裝WSL"></a>安裝WSL</h2><p>如果你是linux 使用者可以跳過這個步驟，windows使用者建議安裝Windows子系統(WSL)，直接在Windows 執行Linux，請先確認windows版本是 Windows 10 版本 2004(組建 19041 和更新版本)或 Windows 11以上的版本才能安裝WSL。<br>先搜尋PowerShell，以系統管理員開啟 PowerShell執行WSL並安裝linux ubuntu，安裝完畢後要重新開機。</p>
<h3 id="install-wsl"><a href="#install-wsl" class="headerlink" title="install wsl"></a>install wsl</h3><p>安裝WSL並且安裝linux ubuntu。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ wsl --install</span><br></pre></td></tr></table></figure>
<p>安裝完畢，重新開機</p>
<h3 id="更新ubuntu"><a href="#更新ubuntu" class="headerlink" title="更新ubuntu"></a>更新ubuntu</h3><p>重新開機後，開啟wsl，更新ubuntu到最新版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo apt update -y &amp;&amp; sudo apt upgrade -y</span><br></pre></td></tr></table></figure>

<h3 id="更新系統套件到最新版本"><a href="#更新系統套件到最新版本" class="headerlink" title="更新系統套件到最新版本"></a>更新系統套件到最新版本</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$sudo apt update &amp;&amp; upgrade</span><br></pre></td></tr></table></figure>
<h3 id="安裝curl-套件"><a href="#安裝curl-套件" class="headerlink" title="安裝curl 套件"></a>安裝curl 套件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$sudo apt install curl</span><br></pre></td></tr></table></figure>
<h3 id="安裝anaconda"><a href="#安裝anaconda" class="headerlink" title="安裝anaconda"></a>安裝anaconda</h3><p>###先建立一個資料夾</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$mkdir temp</span><br></pre></td></tr></table></figure>

<p>###進入資料夾</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$cd temp</span><br></pre></td></tr></table></figure>
<p>###下載anaconda.sh </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$curl https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh --output anaconda.sh</span><br></pre></td></tr></table></figure>
<p>###安裝anaconda</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$bash anaconda.sh</span><br></pre></td></tr></table></figure>

<h3 id="新增conda-指令"><a href="#新增conda-指令" class="headerlink" title="新增conda 指令"></a>新增conda 指令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="確認conda-有安裝成功"><a href="#確認conda-有安裝成功" class="headerlink" title="確認conda 有安裝成功"></a>確認conda 有安裝成功</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$conda info</span><br></pre></td></tr></table></figure>


<h2 id="使用anaconda和pip安裝akasha套件"><a href="#使用anaconda和pip安裝akasha套件" class="headerlink" title="使用anaconda和pip安裝akasha套件"></a>使用anaconda和pip安裝akasha套件</h2><p>Linux使用者安裝完畢anaconda，進行安裝akasha套件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">###create environment</span><br><span class="line">$ conda create --name py3-8 python=3.8</span><br><span class="line">$ activate py3-8</span><br><span class="line"></span><br><span class="line">###install akasha</span><br><span class="line">$ pip install akasha-terminal</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="在Python中使用"><a href="#在Python中使用" class="headerlink" title="在Python中使用"></a>在Python中使用</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#PYTHON3.8</span></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">response = ak.get_response(dir_path, prompt, model=<span class="string">&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;</span>)</span><br></pre></td></tr></table></figure>
</br>
</br>

<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><p>在terminal上輸入，便會開起streamlit使用介面</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ akasha ui</span><br></pre></td></tr></table></figure>
</br>

<p>在瀏覽器中開啟 <a href="http://localhost:8501/">http://localhost:8501/</a> <img src="https://hackmd.io/_uploads/Hkh8vijKT.png" alt="ui_5"> </p>
</br>
</br>

<h2 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h2><p>透過command line interface使用akasha，你可以用’keep-responsing’來建立一個文檔問答模型，並可以提出不同的問題，根據給定目錄中的文檔獲取語言模型的回答。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-responsing -d ../doc/plc/  -c 400 -k 1</span></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 應回收廢塑膠容器材質種類不包含哪種?  聚丙烯（PP） 聚苯乙烯（PS） 聚氯乙烯（PVC）  低密度聚乙烯（LDPE）</span><br><span class="line">Response:  應回收廢塑膠容器材質種類不包含低密度聚乙烯（LDPE）。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 所謂市盈率，是指每股市價除以每股盈餘，也就是股票的?   本益比  帳面值比  派息   資金</span><br><span class="line">英國和德國等多個市場。然而，義大利、加拿大和澳洲並不在這些可交易的國家之列。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : exit()</span><br></pre></td></tr></table></figure>

</br>
</br>

<p>現在可使用的指令: <em><strong>get-response</strong></em>, <em><strong>keep-responsing</strong></em>, <em><strong>chain-of-thought</strong></em>, <em><strong>auto-create-questionset</strong></em> and <em><strong>auto-evaluation</strong></em>.</p>
</br>


<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-responsing --<span class="built_in">help</span></span></span><br><span class="line">Usage: akasha keep-responsing [OPTIONS]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -d, --doc_path TEXT         document directory path, parse all .txt, .pdf,</span><br><span class="line">                              .docx files in the directory  [required]</span><br><span class="line">  -e, --embeddings TEXT       embeddings for storing the documents</span><br><span class="line">  -c, --chunk_size INTEGER    chunk size for storing the documents</span><br><span class="line">  -m, --model TEXT            llm model for generating the response</span><br><span class="line">  -ur --use_rerank BOOL       use rerank to sort the documents</span><br><span class="line">  -t, --threshold FLOAT       threshold score for selecting the relevant</span><br><span class="line">                              documents</span><br><span class="line">  -l, --language TEXT         language for the documents, default is &#x27;ch&#x27; for</span><br><span class="line">                              chinese</span><br><span class="line">  -s, --search_type TEXT      search type for the documents, include merge,</span><br><span class="line">                              svm, mmr, tfidf</span><br><span class="line">  -sys, --system_prompt TEXT  system prompt for the llm model</span><br><span class="line">  -md, --max_doc_len INTEGER    max document length for the llm model input</span><br><span class="line">  --help                      Show this message and exit.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>安裝&amp;設定</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>嵌入模型</title>
    <url>/2024/12/26/%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="選擇不同嵌入模型"><a href="#選擇不同嵌入模型" class="headerlink" title="選擇不同嵌入模型"></a>選擇不同嵌入模型</h2><p>使用參數<em><strong>embeddings</strong></em>便可以選擇不同的嵌入模型，預設是<em><strong>openai:text-embedding-ada-002</strong></em>.</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><h3 id="1-openai"><a href="#1-openai" class="headerlink" title="1. openai"></a>1. openai</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.Doc_QA()</span><br><span class="line">ak.get_response(dir_path, prompt, embeddings=&quot;openai:text-embedding-ada-002&quot;,)</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="2-huggingface"><a href="#2-huggingface" class="headerlink" title="2. huggingface"></a>2. huggingface</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(embeddings=&quot;huggingface:all-MiniLM-L6-v2&quot;)</span><br><span class="line">resposne = ak.get_response(dir_path, prompt)</span><br></pre></td></tr></table></figure>
</br>
</br>



<h2 id="可使用的模型"><a href="#可使用的模型" class="headerlink" title="可使用的模型"></a>可使用的模型</h2><p>:::info<br>每個嵌入模型都有max sequence length，超過的話後面的文字就會被截斷，不會拿進去做嵌入。<br>:::</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">openai_emd = &quot;openai:text-embedding-ada-002&quot;  # need environment variable &quot;OPENAI_API_KEY&quot;  # 8192 max seq length</span><br><span class="line">huggingface_emd = &quot;hf:all-MiniLM-L6-v2&quot; </span><br><span class="line">text2vec_ch_emd = &quot;hf:shibing624/text2vec-base-chinese&quot;   # 128 max seq length </span><br><span class="line">text2vec_mul_emd = &quot;hf:shibing624/text2vec-base-multilingual&quot;  # 256 max seq length</span><br><span class="line">text2vec_ch_para_emd = &quot;hf:shibing624/text2vec-base-chinese-paraphrase&quot; # perform better for long text, 256 max seq length</span><br><span class="line">bge_en_emd = &quot;hf:BAAI/bge-base-en-v1.5&quot;  # 512 max seq length</span><br><span class="line">bge_ch_emd = &quot;hf:BAAI/bge-base-zh-v1.5&quot;  # 512 max seq length</span><br><span class="line"></span><br><span class="line">rerank_base = &quot;rerank:BAAI/bge-reranker-base&quot;    # 512 max seq length</span><br><span class="line">rerank_large = &quot;rerank:BAAI/bge-reranker-large&quot;  # 512 max seq length</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>
</br>
</br>


<h2 id="自訂嵌入模型"><a href="#自訂嵌入模型" class="headerlink" title="自訂嵌入模型"></a>自訂嵌入模型</h2><p>如果你想使用其他模型，可以建立一個輸入是<em><strong>texts:list</strong></em>的函數，代表的是文件庫中所有分割好的文字段落，此函數需回傳embedding之後每段文字的向量，並將此函數作為<em><strong>embeddings</strong></em>參數</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>我們建立一個test_embed函數，並可以將它作為參數輸入進get_response回答問題</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def test_embed(texts:list)-&gt;list:</span><br><span class="line"></span><br><span class="line">    from sentence_transformers import SentenceTransformer</span><br><span class="line">    mdl = SentenceTransformer(&#x27;BAAI/bge-large-zh-v1.5&#x27;)</span><br><span class="line">    embeds =  mdl.encode(texts,normalize_embeddings=True)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    return embeds</span><br><span class="line"></span><br><span class="line">doc_path = &quot;./mic/&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line"></span><br><span class="line">qa = akasha.Doc_QA(verbose=True, search_type = &quot;svm&quot;, embeddings = test_embed)</span><br><span class="line">qa.get_response(doc_path= doc_path, prompt = prompt)</span><br></pre></td></tr></table></figure>


<h2 id="建立Embeddings物件"><a href="#建立Embeddings物件" class="headerlink" title="建立Embeddings物件"></a>建立Embeddings物件</h2><p>以上使用embeddings參數選擇模型後，便會在Doc_QA物件內建立模型的物件embeddings_obj(Embeddings)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">AK = akasha.Doc_QA(embeddings=&quot;openai:text-embedding-ada-002&quot;)</span><br><span class="line"></span><br><span class="line">print(type(AK.embeddings_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<p>也可以使用輔助函數建立Embeddings物件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">embeddings_obj = akasha.handle_embeddings(&quot;openai:text-embedding-ada-002&quot;,verbose=False)</span><br><span class="line"></span><br><span class="line">print(type(embeddings_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<p>此Embeddings物件也可直接傳入Doc_QA，避免重複宣告</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-3.5-turbo&quot;,verbose=False,temperature=0.0)</span><br><span class="line">embeddings_obj = akasha.handle_embeddings(&quot;openai:text-embedding-ada-002&quot;,verbose=False)</span><br><span class="line">AK = Doc_QA(model=model_obj, embeddings=embeddings_obj) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="取出特定文件db"><a href="#取出特定文件db" class="headerlink" title="取出特定文件db"></a>取出特定文件db</h2><p>當你想從大量文檔db中取出特定的文件db，以縮小搜尋範圍時，可以使用 <em><strong>extract_db_by_file</strong></em> (by file source name) 或 <em><strong>extract_db_by_keyword</strong></em> (by id)</p>
<h3 id="example-1"><a href="#example-1" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">emb_name = &quot;openai:text-embedding-ada-002&quot;</span><br><span class="line">emb_obj = akasha.handle_embeddings(emb_name, False)</span><br><span class="line">doc_path = [&quot;文檔資料夾1&quot;,&quot;文檔資料夾2&quot;]</span><br><span class="line">db, _ = akasha.db.processMultiDB(doc_path, True, emb_obj,</span><br><span class="line">                emb_name, chunk_size=1000, ignore_check=True)</span><br><span class="line"></span><br><span class="line">## extract from db ##</span><br><span class="line">file_name_list = [&quot;f1.txt&quot;, &quot;g2.docx&quot;, &quot;h3.pdf&quot;]</span><br><span class="line">ex_db = akasha.extract_db_by_file(db, file_name_list)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>代理</title>
    <url>/2024/12/26/%E4%BB%A3%E7%90%86/</url>
    <content><![CDATA[<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>使用代理(agent)可以賦予語言模型其他能力，以便完成你下的指令，例如提供文件编辑、google搜尋的工具，便可以使語言模型提供更準確地回答，也可以請他幫忙儲存或刪除文件。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><p>在範例1中，創建了一個可以讓使用者輸入文字的工具，也提供給代理一個將文字儲存成json檔案的工具。創建代理後，我們指示它詢問用戶問題，並將結果儲存到default.json中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">input_func</span>(<span class="params">question: <span class="built_in">str</span></span>):</span><br><span class="line">    response = <span class="built_in">input</span>(question)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(&#123;<span class="string">&quot;question&quot;</span>: question, <span class="string">&quot;answer&quot;</span>: response&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_tool = akasha.create_tool(</span><br><span class="line">    <span class="string">&quot;user_question_tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;This is the tool to ask user question, the only one param question is the question string that has not been answered and we want to ask user.&quot;</span>,</span><br><span class="line">    func=input_func)</span><br><span class="line"></span><br><span class="line">ao = akasha.test_agent(verbose=<span class="literal">True</span>,</span><br><span class="line">                    tools=[</span><br><span class="line">                        input_tool,</span><br><span class="line">                        akasha.get_saveJSON_tool(),</span><br><span class="line">                    ],</span><br><span class="line">                    model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    ao(<span class="string">&quot;逐個詢問使用者以下問題，若所有問題都回答了，則將所有問題和回答儲存成default.json並結束。問題為:1.房間燈關了嗎? \n2. 有沒有人在家?  \n3.有哪些電器開啟?\n&quot;</span></span><br><span class="line">        ))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">I have successfully saved all the questions and answers into the &quot;default.json&quot; file. The conversation is now complete.</span><br><span class="line"></span><br><span class="line">### default.json ###</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;房間燈關了嗎?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;no&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;有沒有人在家?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;no&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;有哪些電器開啟?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;phone, shower&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>

<p>在範例二中，我們添加了wikipedia工具，讓語言模型能透過Wikipedia API查詢必要的資訊來幫助回答。由於wiki的回答中可能包含不必要的資訊，我們可以使用retri_observation來擷取與問題有關的回答。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">ao = akasha.test_agent(</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">        tools=[input_tool,</span><br><span class="line">               akasha.get_saveJSON_tool(),</span><br><span class="line">               akasha.get_wiki_tool()],</span><br><span class="line">        retri_observation=<span class="literal">True</span>,</span><br><span class="line">        model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ao(<span class="string">&quot;請用中文回答李遠哲跟黃仁勳誰比較老?將查到的資訊和答案儲存成json檔案，檔名為AGE.json&quot;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">根據查到的資訊，李遠哲（Yuan T. Lee）比黃仁勳（Jensen Huang）更老。李遠哲於1936年11月19日出生，而黃仁勳的出生日期是1963年2月17日。我已將這些資訊儲存成名為&quot;AGE.json&quot;的</span><br><span class="line">JSON檔案。</span><br><span class="line"></span><br><span class="line">### AGE.json ###</span><br><span class="line">&#123;</span><br><span class="line">    &quot;李遠哲&quot;: &quot;1936-11-19&quot;,</span><br><span class="line">    &quot;黃仁勳&quot;: &quot;1963-02-17&quot;,</span><br><span class="line">    &quot;答案&quot;: &quot;李遠哲比黃仁勳更老&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h3><p>若你想及時得到每輪agent的回應，可以使用stream function，此函式將每輪agent的回應回傳為generator</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">ao = akasha.test_agent(</span><br><span class="line">        verbose=True,</span><br><span class="line">        tools=[input_tool,</span><br><span class="line">               akasha.get_saveJSON_tool(),</span><br><span class="line">               akasha.get_wiki_tool()],</span><br><span class="line">        retri_observation=True,</span><br><span class="line">        model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line">st = ao.stream(&quot;請用中文回答李遠哲跟黃仁勳誰比較老?將查到的資訊和答案儲存成json檔案，檔名為AGE.json&quot;)</span><br><span class="line">for s in st:</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>

</br>
</br>
</br>
</br>

<h3 id="test-agent-中的所有參數"><a href="#test-agent-中的所有參數" class="headerlink" title="test_agent 中的所有參數:"></a>test_agent 中的所有參數:</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Args:</span><br><span class="line">   model (str, optional): 使用的大語言模型. Defaults to &quot;gpt-3.5-turbo&quot;.\n</span><br><span class="line">   verbose (bool, optional): 是否顯示log文字. Defaults to False.\n</span><br><span class="line">   language (str, optional): 用來計算文字長度(max_doc_len)的語言. Defaults to &quot;zh&quot;</span><br><span class="line">   temperature (float, optional): 大語言模型的temperature(0.0 ~ 1.0) . Defaults to 0.0.\n</span><br><span class="line">   keep_logs (bool, optional)**: 是否紀錄執行的log. Defaults to False.\n</span><br><span class="line">   max_round (int, optional)**: agent最多執行次數，超過即跳出，避免無線迴圈. Defaults to 20.\n</span><br><span class="line">   max_doc_len (int, optional): agent保留的之前做過的思考與動作的文字最大長度. Defaults to 1800.\n</span><br><span class="line">   max_past_observation (int, optional)**: agent保留的之前做過的思考與動作的最多次數. Defaults to 10.\n</span><br><span class="line">   retri_observation (bool, optional)**: 若設為True, agent會利用大語言模型去擷取tool回傳內容，避免多餘文字輸入. Defaults to False.\n</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>批量推理</title>
    <url>/2024/12/26/%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86/</url>
    <content><![CDATA[<h2 id="批量推理"><a href="#批量推理" class="headerlink" title="批量推理"></a>批量推理</h2><p>如果你有大量不需要連貫的推理需求，可以使用<strong>akasha.helper.call_batch_model</strong> 來進行批量推理來提升速度。</p>
<h3 id="call-batch-model"><a href="#call-batch-model" class="headerlink" title="call_batch_model"></a>call_batch_model</h3><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">def call_batch_model(model: LLM, prompt: List[str], </span><br><span class="line">    system_prompt: Union[List[str], str] = &quot;&quot;) -&gt; List[str]:</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">model_obj = akasha.helper.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line"><span class="comment"># this prompt ask LLM to response &#x27;yes&#x27; or &#x27;no&#x27; if the document segment is relevant to the user question or not.</span></span><br><span class="line">SYSTEM_PROMPT = akasha.prompts.default_doc_grader_prompt() </span><br><span class="line">documents = [<span class="string">&quot;Doc1...&quot;</span>, <span class="string">&quot;Doc2...&quot;</span>, <span class="string">&quot;Doc3...&quot;</span>, <span class="string">&quot;Doc4...&quot;</span>]</span><br><span class="line">question = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line"></span><br><span class="line">prompts = [<span class="string">&quot;document: &quot;</span> + doc +<span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;User Question: &quot;</span>+ question <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line"></span><br><span class="line">response_list = call_batch_model(model_obj, prompt, SYSTEM_PROMPT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## [&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>文件搜尋</title>
    <url>/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/</url>
    <content><![CDATA[<h2 id="選擇不同的文件搜尋方法"><a href="#選擇不同的文件搜尋方法" class="headerlink" title="選擇不同的文件搜尋方法"></a>選擇不同的文件搜尋方法</h2><p>使用<em><strong>search_type</strong></em>參數可選擇不同的文件搜尋方法去找出與問題相關的文件段落，可使用<em><strong>svm</strong></em>, <em><strong>mmr</strong></em>, <em><strong>tfidf</strong></em>, <em><strong>knn</strong></em>。另可使用<em><strong>merge</strong></em>，為前三者的合併。</p>
<ol>
<li><p><em><strong>支持向量機（svm）</strong></em> 使用輸入提示和文件向量來訓練svm模型，訓練後，svm可用於基於其與訓練數據的相似性對新向量進行評分。</p>
</li>
<li><p><em><strong>Max Marginal Relevance（mmr）</strong></em> 通過余弦相似度選擇相似的文件，但它也考慮多樣性，因此它還會懲罰與已選擇文件的接近。</p>
</li>
<li><p><em><strong>詞頻-逆文檔頻率（tfidf）</strong></em> 是信息檢索和文本挖掘中常用的權重技術。TF-IDF是一種統計方法，用於評估詞語在一個文檔集合或語料庫中相對於該集合中的一個特定文檔的重要性。</p>
</li>
<li><p><em><strong>K-最近鄰居（KNN）</strong></em> 是一種機器學習算法，用於分類和回歸問題。對於新數據點，它計算其與已知數據點的距離，然後基於最近的 k 個鄰居來預測類別或數值。在分類中，以多數票決定類別，而在回歸中則計算鄰居的平均值。</p>
</li>
<li><p>***Okapi BM25(bm25)***（BM 是最佳匹配的縮寫）是一種基於查詢詞出現在每個文檔中的檢索功能，而不考慮它們在文檔中的相鄰關系的排名一組文檔的方法。它是一系列具有略有不同組件和參數的評分函數。</p>
</br>
</br></li>
</ol>
<h2 id="自動選擇搜尋方法"><a href="#自動選擇搜尋方法" class="headerlink" title="自動選擇搜尋方法"></a>自動選擇搜尋方法</h2><p><em><strong>auto</strong></em>是另一種可以選擇的文件搜尋策略，使用<em><strong>bm25</strong></em>&#x2F;<em><strong>tfidf</strong></em>來搜尋相同詞語的文件，並用svm搜尋近似詞意的文件，若兩者皆沒有找到，則使用rerank模型去遍歷文件，但會相當緩慢。</p>
<h2 id="自訂搜尋方法"><a href="#自訂搜尋方法" class="headerlink" title="自訂搜尋方法"></a>自訂搜尋方法</h2><p>如果你希望設計自己的方法找尋最相似的文檔，可以建立search_type函數，並將此函數作為<em><strong>search_type</strong></em>參數</p>
<p>此函數輸入包含:</p>
<h5 id="1-query-embeds-查詢的嵌入。（numpy-array）"><a href="#1-query-embeds-查詢的嵌入。（numpy-array）" class="headerlink" title="1.query_embeds: 查詢的嵌入。（numpy array）"></a>1.query_embeds: 查詢的嵌入。（numpy array）</h5><h5 id="2-docs-embeds-所有文檔的嵌入。（表示文檔嵌入的-numpy-數組的list）"><a href="#2-docs-embeds-所有文檔的嵌入。（表示文檔嵌入的-numpy-數組的list）" class="headerlink" title="2.docs_embeds: 所有文檔的嵌入。（表示文檔嵌入的 numpy 數組的list）"></a>2.docs_embeds: 所有文檔的嵌入。（表示文檔嵌入的 numpy 數組的list）</h5><h5 id="3-k-所要選擇的最相關文檔的數量。（integer）"><a href="#3-k-所要選擇的最相關文檔的數量。（integer）" class="headerlink" title="3.k: 所要選擇的最相關文檔的數量。（integer）"></a>3.k: 所要選擇的最相關文檔的數量。（integer）</h5><h5 id="4-relevancy-threshold-相關性閾值。如果查詢和文檔之間的距離小於-relevancy-threshold，則選擇該文檔。（float）"><a href="#4-relevancy-threshold-相關性閾值。如果查詢和文檔之間的距離小於-relevancy-threshold，則選擇該文檔。（float）" class="headerlink" title="4.relevancy_threshold: 相關性閾值。如果查詢和文檔之間的距離小於 relevancy_threshold，則選擇該文檔。（float）"></a>4.relevancy_threshold: 相關性閾值。如果查詢和文檔之間的距離小於 relevancy_threshold，則選擇該文檔。（float）</h5><h5 id="5-log-一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）"><a href="#5-log-一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）" class="headerlink" title="5.log: 一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）"></a>5.log: 一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）</h5></br>
</br>

<h4 id="此函數須回傳相似文檔的index順序-list"><a href="#此函數須回傳相似文檔的index順序-list" class="headerlink" title="此函數須回傳相似文檔的index順序(list)"></a>此函數須回傳相似文檔的index順序(list)</h4></br>
</br>


<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>如範例，我們使用歐幾里得距離度量來識別最相關的文檔。它返回一個表示距離小於指定閾值的查詢和文檔嵌入之間的前 k 個文檔的索引列表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def cust(query_embeds, docs_embeds, k:int, relevancy_threshold:float, log:dict):</span><br><span class="line">    </span><br><span class="line">    from scipy.spatial.distance import euclidean</span><br><span class="line">    import numpy as np</span><br><span class="line">    distance = [[euclidean(query_embeds, docs_embeds[idx]),idx] for idx in range(len(docs_embeds))]</span><br><span class="line">    distance = sorted(distance, key=lambda x: x[0])</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    ## change dist if embeddings not between 0~1</span><br><span class="line">    max_dist = 1</span><br><span class="line">    while max_dist &lt; distance[-1][0]:</span><br><span class="line">        max_dist *= 10</span><br><span class="line">        relevancy_threshold *= 10</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    ## add log para</span><br><span class="line">    log[&#x27;dd&#x27;] = &quot;miao&quot;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    return  [idx for dist,idx in distance[:k] if (max_dist - dist) &gt;= relevancy_threshold]</span><br><span class="line"></span><br><span class="line">doc_path = &quot;./mic/&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line"></span><br><span class="line">qa = akasha.Doc_QA(verbose=True, search_type = cust, embeddings=&quot;hf:shibing624/text2vec-base-chinese&quot;)</span><br><span class="line">qa.get_response(doc_path= doc_path, prompt = prompt)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>提示格式</title>
    <url>/2024/12/26/%E6%8F%90%E7%A4%BA%E6%A0%BC%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="提示格式"><a href="#提示格式" class="headerlink" title="提示格式"></a>提示格式</h2><p>根據使用的語言模型不同，使用不同的格式來下指令可以得到更好的結果，akasha目前提供 <em><strong>gpt</strong></em>, <em><strong>llama</strong></em>, <em><strong>chat_gpt</strong></em>, <em><strong>chat_mistral</strong></em>等格式</p>
<h4 id="gpt"><a href="#gpt" class="headerlink" title="gpt"></a>gpt</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = System: &#123;system_prompt&#125; \n\n &#123;history_messages&#125; \n\n Human: &#123;prompt&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="llama"><a href="#llama" class="headerlink" title="llama"></a>llama</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = [INST] &lt;&lt;SYS&gt;&gt;  &#123;system_prompt&#125; \n\n &lt;&lt;SYS&gt;&gt; &#123;history_messages&#125; \n\n  &#123;prompt&#125; [\INST]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="chat-gpt"><a href="#chat-gpt" class="headerlink" title="chat_gpt"></a>chat_gpt</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = [&#123;&quot;role&quot;:&quot;system&quot;, &quot;content&quot;: &#123;system_prompt&#125; &#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;history msg1&#125;&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;assistant&quot;, &quot;content&quot;: &#123;history msg2&#125;&#125;,</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;prompt&#125;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="chat-mistral"><a href="#chat-mistral" class="headerlink" title="chat_mistral"></a>chat_mistral</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = [&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &quot;start conversation&quot; &#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;assistant&quot;, &quot;content&quot;: &#123;system_prompt&#125;&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;history msg1&#125;&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;assistant&quot;, &quot;content&quot;: &#123;history msg2&#125;&#125;,</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;prompt&#125;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">sys_prompt = &quot;請用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是甚麼?&quot;</span><br><span class="line">qa = akasha.Doc_QA(</span><br><span class="line">    verbose=False, </span><br><span class="line">    search_type=&quot;svm&quot;, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line"></span><br><span class="line">response = qa.get_response(</span><br><span class="line">        doc_path=&quot;docs/mic/&quot;,</span><br><span class="line">        prompt=prompt,</span><br><span class="line">        prompt_format_type=&quot;chat_gpt&quot;,</span><br><span class="line">        system_prompt=sys_prompt,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<h3 id="Example2"><a href="#Example2" class="headerlink" title="Example2"></a>Example2</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">sys_prompt = &quot;請用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是甚麼?&quot;</span><br><span class="line">input_text = akasha.prompts.format_sys_prompt(sys_prompt,prompt,&quot;chat_gpt&quot;)</span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-3.5-turbo&quot;,False,0.0)</span><br><span class="line"></span><br><span class="line">response = akasha.call_model(model_obj, input_text)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>目錄</title>
    <url>/2024/12/31/%E7%9B%AE%E9%8C%84/</url>
    <content><![CDATA[<h1 id="目錄"><a href="#目錄" class="headerlink" title="目錄"></a>目錄</h1><h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><ul>
<li><a href="/2024/12/31/2024%20updates/">2024 updates</a></li>
</ul>
<h2 id="安裝-設定"><a href="#安裝-設定" class="headerlink" title="安裝&amp;設定"></a>安裝&amp;設定</h2><ul>
<li><a href="/2024/12/30/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/">安裝&amp;使用</a></li>
<li><a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a></br>
</br></li>
</ul>
<h2 id="文檔問答"><a href="#文檔問答" class="headerlink" title="文檔問答"></a>文檔問答</h2><ul>
<li><a href="/2024/12/29/get_response/">get_response</a></li>
<li><a href="/2024/12/29/chain_of_thought/">chain_of_thought</a></li>
<li><a href="/2024/12/29/ask_whole_file/">ask_whole_file</a></li>
<li><a href="/2024/12/29/ask_self/">ask_self</a></li>
<li><a href="/2024/12/29/ask_agent/">ask_agent</a></li>
<li><a href="/2024/12/29/ask_image/">ask_image</a></br>
</br></li>
</ul>
<h2 id="評估"><a href="#評估" class="headerlink" title="評估"></a>評估</h2><ul>
<li><a href="/2024/12/28/auto_evaluation/">auto_evaluation</a></li>
<li><a href="/2024/12/28/auto_create_questionset/">auto_create_questionset</a></li>
<li><a href="/2024/12/28/optimum_combination/">optimum_combination</a></br>
</br></li>
</ul>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul>
<li><a href="/2024/12/27/summary/">summary</a></li>
</ul>
</br>
</br>

<h2 id="進階"><a href="#進階" class="headerlink" title="進階"></a>進階</h2><ul>
<li><a href="/2024/12/26/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">語言模型</a></li>
<li><a href="/2024/12/26/%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">嵌入模型</a></li>
<li><a href="/2024/12/26/%E6%8F%90%E7%A4%BA%E6%A0%BC%E5%BC%8F/">提示格式</a></li>
<li><a href="/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><a href="/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a></li>
<li><a href="/2024/12/26/%E4%BB%A3%E7%90%86/">代理</a></li>
<li><a href="/2024/12/26/%E6%B5%81%E8%BC%B8%E5%87%BA/">流輸出</a></li>
<li><a href="/2024/12/26/%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86/">批量推理</a></li>
<li><a href="/2024/12/26/FAST%20API/">FAST API</a></li>
</ul>
</br>
</br>

<h2 id="指定輸出格式"><a href="#指定輸出格式" class="headerlink" title="指定輸出格式"></a>指定輸出格式</h2><ul>
<li><a href="/2024/12/25/JSON%E6%A0%BC%E5%BC%8F/">JSON格式</a></li>
<li><a href="/2024/12/25/XML%E6%A0%BC%E5%BC%8F/">XML格式</a></li>
</ul>
</br>
</br>





<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><ul>
<li><a href="/2024/12/24/ui%E8%A8%AD%E5%AE%9A/">ui設定</a></li>
<li><a href="/2024/12/24/ui%E6%93%8D%E4%BD%9C/">ui操作</a></li>
</ul>
</br>
</br>



<h2 id="UI-DEV"><a href="#UI-DEV" class="headerlink" title="UI-DEV"></a>UI-DEV</h2><ul>
<li><a href="/2024/01/01/DEV-%E5%AE%89%E8%A3%9D&%E5%9F%B7%E8%A1%8C/">DEV-安裝&amp;執行</a></li>
<li><a href="/2024/01/01/DEV-%E8%A8%BB%E5%86%8A%E5%B8%B3%E8%99%9F/">DEV-註冊帳號</a></li>
<li><a href="/2024/01/01/DEV-%E8%A8%AD%E5%AE%9A/">DEV-設定</a></li>
<li><a href="/2024/01/01/DEV-Datasets/">DEV-Datasets</a></li>
<li><a href="/2024/01/01/DEV-Knowledges/">DEV-Knowledges</a></li>
<li><a href="/2024/01/01/DEV-Consult/">DEV-Consult</a></li>
</ul>
]]></content>
      <categories>
        <category>目錄</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>流輸出</title>
    <url>/2024/12/26/%E6%B5%81%E8%BC%B8%E5%87%BA/</url>
    <content><![CDATA[<h2 id="call-stream-model"><a href="#call-stream-model" class="headerlink" title="call_stream_model"></a>call_stream_model</h2><p>在輔助函數中，若LLM模型為若為<em><strong>openai</strong></em>, <em><strong>huggingface</strong></em>, <em><strong>remote</strong></em>類模型，可以使用akasha.call_stream_model()來得到流輸出</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">prompt = <span class="string">&quot;say something.&quot;</span></span><br><span class="line">model_obj = akasha.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">streaming = akasha.call_stream_model(model_obj, prompt)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> streaming:</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="Doc-QA-stream"><a href="#Doc-QA-stream" class="headerlink" title="Doc_QA stream"></a>Doc_QA stream</h2><p>Doc_QA class的函式皆可使用參數stream&#x3D;True來得到流輸出</p>
<h2 id="Stream-Output"><a href="#Stream-Output" class="headerlink" title="Stream Output"></a>Stream Output</h2><p>要在網頁上或API中使用流輸出(及時一個字一個字輸出語言模型回答)時，若為<em><strong>openai</strong></em>, <em><strong>huggingface</strong></em>, <em><strong>remote</strong></em>類模型，可以使用model_obj.stream(prompt)，以下為streamlit write_stream在網頁上即時輸出回答為範例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> gc, torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;pre&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state.pre = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;model_obj&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state.model_obj = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clean</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        gc.collect()</span><br><span class="line">        torch.cuda.ipc_collect()</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_response</span>(<span class="params">prompt:<span class="built_in">str</span>, model_name:<span class="built_in">str</span>=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span></span>):</span><br><span class="line">    <span class="comment"># Mistral-7B-Instruct-v0.3   Llama3-8B-Chinese-Chat</span></span><br><span class="line">    mdl_type = model_name.split(<span class="string">&#x27;:&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    streaming = st.session_state.model_obj.stream(prompt)</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> streaming:</span><br><span class="line">        <span class="keyword">if</span> mdl_type == <span class="string">&quot;openai&quot;</span>:</span><br><span class="line">            <span class="keyword">yield</span> s.content</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> s</span><br><span class="line"></span><br><span class="line">model = st.selectbox(<span class="string">&quot;select model&quot;</span>, [<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,<span class="string">&quot;hf:model/Mistral-7B-Instruct-v0.3&quot;</span>])</span><br><span class="line">prompt = st.chat_input(<span class="string">&quot;Say something&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> st.session_state.pre != model:</span><br><span class="line">    st.session_state.model_obj = <span class="literal">None</span></span><br><span class="line">    clean()</span><br><span class="line">    st.session_state.model_obj = akasha.helper.handle_model(model, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">    st.session_state.pre = model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> prompt:</span><br><span class="line">    st.write(<span class="string">&quot;question: &quot;</span> + prompt)</span><br><span class="line">    st.write_stream(stream_response(prompt, model))</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>使用model_obj &#x3D; akasha.helper.handle_model(model, False, 0.0)建立模型物件，當要使用推論時，使用model_obj.stream(prompt)進行推論，可使用yield讓stream_response函式回傳generator, 便可即時輸出回答。</p>
<h3 id="模型為openai類型時，s-content才是輸出文字，其他類型s即是輸出文字。"><a href="#模型為openai類型時，s-content才是輸出文字，其他類型s即是輸出文字。" class="headerlink" title="模型為openai類型時，s.content才是輸出文字，其他類型s即是輸出文字。"></a>模型為openai類型時，s.content才是輸出文字，其他類型s即是輸出文字。</h3>]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>auto_evaluation</title>
    <url>/2024/12/28/auto_evaluation/</url>
    <content><![CDATA[<h2 id="Auto-Evaluation"><a href="#Auto-Evaluation" class="headerlink" title="Auto Evaluation"></a>Auto Evaluation</h2><p>若要測試各種參數對語言模型回答的好壞，可以使用auto_evalution函數。首先，您需要基於您要使用的文檔構建一個問題集(.txt)。<br>您可以生成單選題文件或問答題文件。</p>
<ol>
<li>對於<em><strong>單選題文件</strong></em>，每個選項和正確答案之間用制表符(\t)分隔，每行是一個問題，如範例: <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">應回收廢塑膠容器材質種類不包含哪種?	1.聚丙烯（PP）	2.聚苯乙烯（PS）	3.聚氯乙烯（PVC）	4.低密度聚乙烯（LDPE）	4</span><br><span class="line">庫存盤點包括庫存全盤作業及不定期抽盤作業，盤點計畫應包括下列項目不包含哪項?	1.盤點差異之處理	2.盤點清冊	3.各項物品存放區域配置圖	4.庫存全盤日期及參加盤點人員名單	1</span><br><span class="line">以下何者不是環保署指定之公民營地磅機構?	1.中森加油站企業有限公司	2.台益地磅站	3.大眾地磅站	4.新福行	4</span><br></pre></td></tr></table></figure>
 函數將返回問題集的正確率和使用的token量，每個問題的詳細內容儲存在logs中。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha.eval as eval</span><br><span class="line">import os</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv() </span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your openAI key&quot;</span><br><span class="line">dir_path = &quot;doc/pvc/&quot;</span><br><span class="line">exp_name = &quot;exp_akasha_auto_evaluation&quot;</span><br><span class="line"></span><br><span class="line">eva = eval.Model_Eval(question_style=&quot;single_choice&quot;, search_type=&#x27;merge&#x27;,\</span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;, embeddings=&quot;openai:text-embedding-ada-002&quot;,record_exp=exp_name)</span><br><span class="line">print(eva.auto_evaluation(&quot;question_pvc.txt&quot;, dir_path ))</span><br><span class="line">## correct rate: 0.9, tokens: 3228 ##</span><br></pre></td></tr></table></figure></li>
<li>對於<em><strong>問答題文件</strong></em>，每個問題之前有 “問題：”，每個參考答案之前有 “答案：”。每個問題之間用兩個換行符 (\n\n) 分隔。 <figure class="highlight text"><table><tr><td class="code"><pre><span class="line">問題：根據文件中的訊息，智慧製造的複雜性已超越系統整合商的負荷程度，未來產業鏈中的角色將傾向朝共和共榮共創智慧製造商機，而非過往的單打獨鬥模式發展。請問為什麼  供  應商、電信商、軟體開發商、平台商、雲端服務供應商、系統整合商等角色會傾向朝共和共榮共創智慧製造商機的方向發展？</span><br><span class="line">答案：因為智慧製造的複雜性已超越系統整合商的負荷程度，單一角色難以完成整個智慧製造的需求，而共和共榮共創的模式可以整合各方的優勢，共同創造智慧製造的商機。</span><br><span class="line"></span><br><span class="line">問題：根據文件中提到的資訊技術商（IT）和營運技術商（OT），請列舉至少兩個邊緣運算產品或解決方案。</span><br><span class="line">答案：根據文件中的資訊，NVIDIA的邊緣運算產品包括Jetson系列和EGX系列，而IBM的邊緣運算產品包括IBM Edge Application Manager和IBM Watson Anywhere。</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>模型評估</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>設定 API Key</title>
    <url>/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/</url>
    <content><![CDATA[<h1 id="openAI-API-Key"><a href="#openAI-API-Key" class="headerlink" title="openAI API Key"></a>openAI API Key</h1></br>
</br>

<h2 id="openAI"><a href="#openAI" class="headerlink" title="openAI:"></a>openAI:</h2><p>如果需要使用openAI的模型，必須先去<a href="https://platform.openai.com/account/api-keys">openai</a>取得API KEY。取得KEY後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-OPENAI-API-KEY"><a href="#2-設定成環境變數-變數名-OPENAI-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:OPENAI_API_KEY)"></a>2.設定成環境變數(變數名:OPENAI_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數"><a href="#3-在terminal中使用export設定環境變數" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key</h5></br>
</br>

<h2 id="Azure-openAI"><a href="#Azure-openAI" class="headerlink" title="Azure openAI"></a>Azure openAI</h2><p>如果你想使用Azure openAI，先去<a href="https://oai.azure.com/portal">azureAI</a>取得base url 和 API key。</p>
<p>將<em><strong>OPENAI_API_KEY&#x3D;your azure key</strong></em>, <em><strong>OPENAI_API_BASE&#x3D;your Language API base url</strong></em>, <em><strong>OPENAI_API_TYPE&#x3D;azure</strong></em>, <em><strong>OPENAI_API_VERSION&#x3D;2023-05-15</strong></em> 寫於.env檔案並放於你要執行akasha的路徑中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## .env file</span><br><span class="line">AZURE_API_KEY=&#123;your azure key&#125;</span><br><span class="line">AZURE_API_BASE=&#123;your Language API base url&#125;</span><br><span class="line">AZURE_API_TYPE=azure</span><br><span class="line">AZURE_API_VERSION=2023-05-15</span><br></pre></td></tr></table></figure>

<p>:::info<br>請記得在<a href="https://oai.azure.com/portal">Azure openAI Studio</a>部署所有你需要的模型，且部署名稱與模型名稱相同。<br>:::</p>
</br>
</br>


<h2 id="LLAMA-2"><a href="#LLAMA-2" class="headerlink" title="LLAMA-2"></a>LLAMA-2</h2><p>如果你想使用原版的meta-llama model，並須先去<a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/">meta-llama</a>去取得授權，並註冊<a href="https://huggingface.co/login?next=/settings/tokens">huggingface</a>取得access token，取得授權後才能經由huggingface下載並使用模型。<br><img src="https://hackmd.io/_uploads/H1LOb2ot6.png" alt="granted"></p>
<p>:::info<br>the account on Hugging Face and the email you use to request access to Meta-Llama must be the same, so that you can download models from Hugging Face once your account is approved.</p>
<p>You should see the Gated model You have been granted access to this model once your account is approved<br>:::</p>
</br>
</br>


<p>同樣的，取得huggingface key值後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中HF-TOKEN-your-api-key"><a href="#1-將KEY放於-env檔案中HF-TOKEN-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key"></a>1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-HF-TOKEN"><a href="#2-設定成環境變數-變數名-HF-TOKEN" class="headerlink" title="2.設定成環境變數(變數名:HF_TOKEN)"></a>2.設定成環境變數(變數名:HF_TOKEN)</h5><h5 id="3-在terminal中使用export設定環境變數-1"><a href="#3-在terminal中使用export設定環境變數-1" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key"><a href="#4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#PYTHON3.8</span><br><span class="line"># os.environ[&#x27;HF_TOKEN&#x27;]=your api key</span><br><span class="line">import akasha</span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">response = ak.get_response(dir_path, prompt, model=&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>安裝&amp;設定</category>
      </categories>
      <tags>
        <tag>akasha</tag>
      </tags>
  </entry>
  <entry>
    <title>輔助函數</title>
    <url>/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/</url>
    <content><![CDATA[<h2 id="儲存紀錄"><a href="#儲存紀錄" class="headerlink" title="儲存紀錄"></a>儲存紀錄</h2><p>每次執行akasha 的任何函數時，如果使用參數keep_logs&#x3D;True，它都會保存此次運行的參數和結果到logs。每個運行都有一個timestamp，您可以使用 {obj_name}.timestamp_list 來查看它們，並使用它來找到您想要查看的logs。<br>您還可以將logs保存為 .txt 文件或 .json 文件。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><p>執行完get_response後，可以利用timestamp獲取log，也可以使用<em><strong>save_logs</strong></em>來保存log</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">qa = akasha.Doc_QA(verbose=False, keep_logs=True, search_type=&quot;merge&quot;, max_doc_len=1500,model=&quot;llama-gpu:model/chinese-alpaca-2-7b.Q5_K_S.gguf&quot;)</span><br><span class="line">query1 = &quot;五軸是什麼&quot;</span><br><span class="line">qa.get_response(doc_path=&quot;./doc/mic/&quot;, prompt = query1)</span><br><span class="line"></span><br><span class="line">tp = qa.timestamp_list</span><br><span class="line">print(tp)</span><br><span class="line">## [&quot;2023/09/26, 10:52:36&quot;, &quot;2023/09/26, 10:59:49&quot;, &quot;2023/09/26, 11:09:23&quot;]</span><br><span class="line"></span><br><span class="line">print(qa.logs[tp[-1]])</span><br><span class="line">## &#123;&quot;fn_type&quot;:&quot;get_response&quot;,&quot;search_type&quot;:&quot;merge&quot;, &quot;max_doc_len&quot;:1500,.....&quot;response&quot;:....&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">qa.save_logs(file_name=&quot;logs.json&quot;,file_type=&quot;json&quot;)</span><br></pre></td></tr></table></figure>

<p><img src="https://hackmd.io/_uploads/SyfwoYk5T.png" alt="logs"></p>
</br>
</br>


<h2 id="AiiDO"><a href="#AiiDO" class="headerlink" title="AiiDO"></a>AiiDO</h2><p>akasha也可以利用AiiDO來保存執行紀錄，您需要在 AiiDO 平台上創建一個項目。完成後，您將收到自動上傳實驗所需的所有參數。<br>在程序的同一目錄下創建一個 .env 文件，並貼上所有參數。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">##.env file</span><br><span class="line">MINIO_URL= YOUR_MINIO_URL</span><br><span class="line">MINIO_USER= YOUR_MINIO_USER</span><br><span class="line">MINIO_PASSWORD= YOUR_MINIO_PASSWORD</span><br><span class="line">TRACKING_SERVER_URI= YOUR_TRACKING_SERVER_URI</span><br></pre></td></tr></table></figure>



<p>在創建了 .env 文件之後，您可以使用 record_exp 來設置實驗名稱，它將自動記錄實驗指標和結果到 mlflow 服務器。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">import os</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv() </span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your openAI key&quot;</span><br><span class="line"></span><br><span class="line">dir_path = &quot;doc/&quot;</span><br><span class="line">prompt = &quot;「塞西莉亞花」的花語是什麼?	「失之交臂的感情」	「赤誠的心」	「浪子的真情」	「無法挽回的愛」&quot;</span><br><span class="line">exp_name = &quot;exp_akasha_get_response&quot;</span><br><span class="line">ak = akasha.Doc_QA(record_exp=exp_name)</span><br><span class="line">response = ak.get_response(dir_path, prompt)</span><br></pre></td></tr></table></figure>

</br>
</br>


<h4 id="在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding-search-type-and-model-name的組合"><a href="#在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding-search-type-and-model-name的組合" class="headerlink" title="在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding, search type and model name的組合"></a>在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding, search type and model name的組合</h4><p><img src="https://hackmd.io/_uploads/rkSjnt19p.png" alt="upload_experiments"></p>
</br>
</br>

<h4 id="你也可以直接比較不同次實驗的結果"><a href="#你也可以直接比較不同次實驗的結果" class="headerlink" title="你也可以直接比較不同次實驗的結果"></a>你也可以直接比較不同次實驗的結果</h4><p><img src="https://hackmd.io/_uploads/SyvahY1qp.png" alt="response_comparison"></p>
</br>
</br>


<h2 id="翻譯器"><a href="#翻譯器" class="headerlink" title="翻譯器"></a>翻譯器</h2><p>helper模組中提供寫好的函數<em><strong>call_translator</strong></em>讓LLM協助翻譯回答，如以下的範例使用語言模型將中文的回答翻譯成英文。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ak = akasha.Doc_QA(verbose=False, search_type=&quot;auto&quot;)</span><br><span class="line"></span><br><span class="line">response = ak.get_response(doc_path=&quot;docs/mic/&quot;, prompt=&quot;五軸是什麼?&quot;)</span><br><span class="line"></span><br><span class="line">translated_response = akasha.helper.call_translator(ak.model_obj, response, language=&quot;en&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="JSON-格式輸出器"><a href="#JSON-格式輸出器" class="headerlink" title="JSON 格式輸出器"></a>JSON 格式輸出器</h2><p>helper模組中提供寫好的函數<em><strong>call_JSON_formatter</strong></em>讓LLM協助將回答轉成JSON格式。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ak = akasha.Doc_QA(threshold=0.0,verbose=True,)</span><br><span class="line">response = ak.ask_whole_file(file_path=&quot;docs/resume_pool/A.docx&quot;, prompt=f&#x27;&#x27;&#x27;以上是受試者的履歷，請回答該受試者的學歷、經驗、專長、年資&#x27;&#x27;&#x27;)</span><br><span class="line">formatted_response = akasha.helper.call_JSON_formatter(ak.model_obj, response, keys=[&quot;學歷&quot;, &quot;經驗&quot;, &quot;專長&quot;, &quot;年資&quot;])</span><br><span class="line"></span><br><span class="line">print(formatted_response, type(formatted_response))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;學歷&#x27;: &#x27;xxx大學電資學士班四技&#x27;, &#x27;經驗&#x27;: &#x27;帶班導師xx文理補習班擔任補習班導師／管理人員&#x27;, &#x27;專長&#x27;: &#x27;計算機網路(協定)、資料庫系統、物件導向程式設計、C語言、Python、C++、Gitlab、Jenkins、Git、Linux(Bash shell、Ubuntu), &#x27;年資&#x27;: &#x27;0-1年&#x27;&#125; &lt;class &#x27;dict&#x27;&gt;</span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="call-model"><a href="#call-model" class="headerlink" title="call_model"></a>call_model</h2><p>若要呼叫語言模型，可以使用輔助函數call_model</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line">system_prompt = &quot;用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-e3.5-turbo&quot;, False, 0.0)</span><br><span class="line">input_text = akasha.prompts.format_sys_prompt(system_prompt, prompt, &quot;gpt&quot;)</span><br><span class="line"></span><br><span class="line">response = akasha.call_model(model_obj, input_text)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="call-stream-model"><a href="#call-stream-model" class="headerlink" title="call_stream_model"></a>call_stream_model</h2><p>若要呼叫語言模型即時回答，可以使用輔助函數call_stream_model</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">system_prompt = &quot;用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-e3.5-turbo&quot;, False, 0.0)</span><br><span class="line">input_text = akasha.prompts.format_sys_prompt(system_prompt, prompt, &quot;gpt&quot;)</span><br><span class="line"></span><br><span class="line">streaming = akasha.call_stream_model(model_obj, input_text)</span><br><span class="line"></span><br><span class="line">for s in streaming:</span><br><span class="line">    print(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="call-batch-model"><a href="#call-batch-model" class="headerlink" title="call_batch_model"></a>call_batch_model</h2><p>如果你有大量不需要連貫的推理需求，可以使用<strong>akasha.helper.call_batch_model</strong> 來進行批量推理來提升速度。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">def call_batch_model(model: LLM, prompt: List[str], </span><br><span class="line">    system_prompt: Union[List[str], str] = &quot;&quot;) -&gt; List[str]:</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">model_obj = akasha.helper.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line"><span class="comment"># this prompt ask LLM to response &#x27;yes&#x27; or &#x27;no&#x27; if the document segment is relevant to the user question or not.</span></span><br><span class="line">SYSTEM_PROMPT = akasha.prompts.default_doc_grader_prompt() </span><br><span class="line">documents = [<span class="string">&quot;Doc1...&quot;</span>, <span class="string">&quot;Doc2...&quot;</span>, <span class="string">&quot;Doc3...&quot;</span>, <span class="string">&quot;Doc4...&quot;</span>]</span><br><span class="line">question = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line"></span><br><span class="line">prompts = [<span class="string">&quot;document: &quot;</span> + doc +<span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;User Question: &quot;</span>+ question <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line"></span><br><span class="line">response_list = call_batch_model(model_obj, prompt, SYSTEM_PROMPT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## [&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="self-rag"><a href="#self-rag" class="headerlink" title="self-rag"></a>self-rag</h2><p>實作<a href="https://github.com/AkariAsai/self-rag">self-rag</a>，利用語言模型來找出與問題相關的文件片段。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">question = &quot;LPWAN和5G的區別是什麼?&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-3.5-turbo&quot;, False, 0.0)</span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = akasha.createDB_directory(&quot;./docs/mic/&quot;, emb_obj, ignore_check=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">retrivers_list = akasha.search.get_retrivers(db2, emb_obj, False, 0.0,</span><br><span class="line">                                             &quot;auto&quot;, &#123;&#125;)</span><br><span class="line"></span><br><span class="line">docs, doc_length, doc_tokens = akasha.search.get_docs(</span><br><span class="line">    db2,</span><br><span class="line">    emb_obj,</span><br><span class="line">    retrivers_list,</span><br><span class="line">    question,</span><br><span class="line">    False,</span><br><span class="line">    &quot;ch&quot;,</span><br><span class="line">    &quot;auto&quot;,</span><br><span class="line">    False,</span><br><span class="line">    model_obj,</span><br><span class="line">    6000,</span><br><span class="line">    compression=False,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">RAGed_docs = akasha.self_RAG(model_obj,</span><br><span class="line">                             question,</span><br><span class="line">                             docs,)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>語言模型</title>
    <url>/2024/12/26/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="選擇不同語言模型"><a href="#選擇不同語言模型" class="headerlink" title="選擇不同語言模型"></a>選擇不同語言模型</h2><p>使用參數<em><strong>model</strong></em>便可以選擇不同的語言模型，預設是<em><strong>openai:gpt-3.5-turbo</strong></em>.</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><h3 id="1-openai"><a href="#1-openai" class="headerlink" title="1. openai"></a>1. openai</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.Doc_QA()</span><br><span class="line">ak.get_response(dir_path, </span><br><span class="line">                prompt, </span><br><span class="line">                embeddings=&quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">                model=&quot;openai:gpt-3.5-turbo&quot;)</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="2-huggingface"><a href="#2-huggingface" class="headerlink" title="2. huggingface"></a>2. huggingface</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">ak.get_response(dir_path, </span><br><span class="line">                prompt, </span><br><span class="line">                embeddings=&quot;huggingface:all-MiniLM-L6-v2&quot;,</span><br><span class="line">                model=&quot;hf:meta-llama/Llama-2-13b-chat-hf&quot;)</span><br></pre></td></tr></table></figure>
</br>
</br>

<h3 id="3-llama-cpp"><a href="#3-llama-cpp" class="headerlink" title="3. llama-cpp"></a>3. llama-cpp</h3><p>llama-cpp允許使用quantized模型並執行在cpu上，你可以從huggingface上下載.gguf llama-cpp 模型，如範例，如果你的模型下載到”model&#x2F;“路徑下，可以使用以下方法加載模型</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">ak.get_response(dir_path, </span><br><span class="line">                prompt, </span><br><span class="line">                embeddings=&quot;huggingface:all-MiniLM-L6-v2&quot;,</span><br><span class="line">                model=&quot;llama-cpu:model/llama-2-13b-chat.Q5_K_S.gguf&quot;)</span><br></pre></td></tr></table></figure>
<p>llama-cpp同樣允許使用gpu運算模型，使用<em><strong>llama-gpu</strong></em></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">ak.get_response(dir_path, </span><br><span class="line">                prompt, </span><br><span class="line">                embeddings=&quot;huggingface:all-MiniLM-L6-v2&quot;,</span><br><span class="line">                model=&quot;llama-gpu:model/llama-2-3b-chat.Q5_K_S.gguf&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="4-遠端api"><a href="#4-遠端api" class="headerlink" title="4. 遠端api"></a>4. 遠端api</h3><p>如果你使用別人的api或者利用TGI (Text Generation Inference)部署自己的模型，你可以使用***remote:{your LLM api url}***來加載模型。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">ak.get_response(dir_path, </span><br><span class="line">                prompt, </span><br><span class="line">                model=&quot;remote:http://140.92.60.189:8081&quot;)</span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="可使用的模型"><a href="#可使用的模型" class="headerlink" title="可使用的模型"></a>可使用的模型</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">openai_model = &quot;openai:gpt-3.5-turbo&quot;  # need environment variable &quot;OPENAI_API_KEY&quot;</span><br><span class="line">huggingface_model = &quot;hf:meta-llama/Llama-2-7b-chat-hf&quot; #need environment variable &quot;HUGGINGFACEHUB_API_TOKEN&quot; to download meta-llama model</span><br><span class="line">quantized_ch_llama_model = &quot;hf:FlagAlpha/Llama2-Chinese-13b-Chat-4bit&quot;</span><br><span class="line">taiwan_llama_gptq = &quot;hf:weiren119/Taiwan-LLaMa-v1.0-4bits-GPTQ&quot;</span><br><span class="line">mistral = &quot;hf:Mistral-7B-Instruct-v0.2&quot; </span><br><span class="line">mediatek_Breeze = &quot;hf:MediaTek-Research/Breeze-7B-Instruct-64k-v0.1&quot;</span><br><span class="line">### If you want to use llama-cpp to run model on cpu, you can download gguf version of models </span><br><span class="line">### from https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF  and the name behind &quot;llama-gpu:&quot; or &quot;llama-cpu:&quot;</span><br><span class="line">### from https://huggingface.co/TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGUF</span><br><span class="line">### is the path of the downloaded .gguf file</span><br><span class="line">llama_cpp_model = &quot;llama-gpu:model/llama-2-13b-chat-hf.Q5_K_S.gguf&quot;  </span><br><span class="line">llama_cpp_model = &quot;llama-cpu:model/llama-2-7b-chat.Q5_K_S.gguf&quot;</span><br><span class="line">llama_cpp_chinese_alpaca = &quot;llama-gpu:model/chinese-alpaca-2-7b.Q5_K_S.gguf&quot;</span><br><span class="line">llama_cpp_chinese_alpaca = &quot;llama-cpu:model/chinese-alpaca-2-13b.Q5_K_M.gguf&quot;</span><br><span class="line">chatglm_model = &quot;chatglm:THUDM/chatglm2-6b&quot;</span><br></pre></td></tr></table></figure>


</br>
</br>
</br>
</br>


<h2 id="自訂語言模型"><a href="#自訂語言模型" class="headerlink" title="自訂語言模型"></a>自訂語言模型</h2><p>如果你想使用其他模型，可以建立一個輸入是prompt的函數並回傳語言模型的回答，並將此函數作為<em><strong>model</strong></em>參數</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>我們建立一個test_model函數，並可以將它作為參數輸入進get_response回答問題</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def test_model(prompt:str):</span><br><span class="line">    </span><br><span class="line">    import openai</span><br><span class="line">    from langchain.chat_models import ChatOpenAI</span><br><span class="line">    openai.api_type = &quot;open_ai&quot;</span><br><span class="line">    model = ChatOpenAI(model=&quot;gpt-3.5-turbo&quot;, temperature = 0)</span><br><span class="line">    ret = model.predict(prompt)</span><br><span class="line">    </span><br><span class="line">    return ret</span><br><span class="line"></span><br><span class="line">doc_path = &quot;./mic/&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line"></span><br><span class="line">qa = akasha.Doc_QA(verbose=True, search_type = &quot;svm&quot;, model = test_model)</span><br><span class="line">qa.get_response(doc_path= doc_path, prompt = prompt)</span><br></pre></td></tr></table></figure>
</br>
</br>
</br>
</br>

<h2 id="建立LLM物件"><a href="#建立LLM物件" class="headerlink" title="建立LLM物件"></a>建立LLM物件</h2><p>以上使用model參數選擇模型後，便會在Doc_QA物件內建立模型的物件model_obj(LLM)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">AK = akasha.Doc_QA(model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line"></span><br><span class="line">print(type(AK.model_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<p>也可以使用輔助函數建立LLM物件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-3.5-turbo&quot;,verbose=False,temperature=0.0)</span><br><span class="line"></span><br><span class="line">print(type(model_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<p>此LLM物件也可直接傳入Doc_QA，避免重複宣告</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-3.5-turbo&quot;,verbose=False,temperature=0.0)</span><br><span class="line"></span><br><span class="line">AK = Doc_QA(model=model_obj) </span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>進階</category>
      </categories>
      <tags>
        <tag>akasha-advanced</tag>
      </tags>
  </entry>
</search>
